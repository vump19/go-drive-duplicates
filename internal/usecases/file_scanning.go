package usecases

import (
	"context"
	"fmt"
	"go-drive-duplicates/internal/domain/entities"
	"go-drive-duplicates/internal/domain/repositories"
	"go-drive-duplicates/internal/domain/services"
	"log"
	"sync"
	"time"
)

// FileScanningUseCase handles file scanning operations
type FileScanningUseCase struct {
	fileRepo        repositories.FileRepository
	progressRepo    repositories.ProgressRepository
	storageProvider services.StorageProvider
	fileService     services.FileService
	progressService services.ProgressService

	// Configuration
	batchSize    int
	workerCount  int
	saveInterval time.Duration
}

// NewFileScanningUseCase creates a new file scanning use case
func NewFileScanningUseCase(
	fileRepo repositories.FileRepository,
	progressRepo repositories.ProgressRepository,
	storageProvider services.StorageProvider,
	fileService services.FileService,
	progressService services.ProgressService,
) *FileScanningUseCase {
	return &FileScanningUseCase{
		fileRepo:        fileRepo,
		progressRepo:    progressRepo,
		storageProvider: storageProvider,
		fileService:     fileService,
		progressService: progressService,
		batchSize:       100,
		workerCount:     3,
		saveInterval:    30 * time.Second,
	}
}

// ScanAllFilesRequest represents the request for scanning all files
type ScanAllFilesRequest struct {
	ResumeFromProgress bool                     `json:"resumeFromProgress"`
	BatchSize          int                      `json:"batchSize,omitempty"`
	WorkerCount        int                      `json:"workerCount,omitempty"`
	ProgressCallback   func(*entities.Progress) `json:"-"`
}

// ScanAllFilesResponse represents the response for scanning all files
type ScanAllFilesResponse struct {
	Progress       *entities.Progress `json:"progress"`
	TotalFiles     int                `json:"totalFiles"`
	ProcessedFiles int                `json:"processedFiles"`
	NewFiles       int                `json:"newFiles"`
	UpdatedFiles   int                `json:"updatedFiles"`
	Errors         []string           `json:"errors,omitempty"`
}

// ScanFolderRequest represents the request for scanning a specific folder
type ScanFolderRequest struct {
	FolderID         string                   `json:"folderId"`
	Recursive        bool                     `json:"recursive"`
	UpdatePaths      bool                     `json:"updatePaths"`
	ProgressCallback func(*entities.Progress) `json:"-"`
}

// ScanFolderResponse represents the response for scanning a folder
type ScanFolderResponse struct {
	Progress       *entities.Progress `json:"progress"`
	TotalFiles     int                `json:"totalFiles"`
	ProcessedFiles int                `json:"processedFiles"`
	NewFiles       int                `json:"newFiles"`
	UpdatedFiles   int                `json:"updatedFiles"`
	FolderPath     string             `json:"folderPath"`
	Errors         []string           `json:"errors,omitempty"`
}

// ScanAllFiles scans all files from the storage provider
func (uc *FileScanningUseCase) ScanAllFiles(ctx context.Context, req *ScanAllFilesRequest) (*ScanAllFilesResponse, error) {
	log.Println("ğŸ” ì „ì²´ íŒŒì¼ ìŠ¤ìº” ì‹œì‘")

	// Apply configuration
	if req.BatchSize > 0 {
		uc.batchSize = req.BatchSize
	}
	if req.WorkerCount > 0 {
		uc.workerCount = req.WorkerCount
	}

	// Check for existing progress
	var progress *entities.Progress
	var err error

	if req.ResumeFromProgress {
		activeProgress, err := uc.progressService.GetActiveOperations(ctx)
		if err == nil && len(activeProgress) > 0 {
			for _, p := range activeProgress {
				if p.OperationType == entities.OperationFileScan {
					progress = p
					log.Printf("ğŸ”„ ê¸°ì¡´ ì§„í–‰ ìƒí™©ì—ì„œ ì¬ê°œ: %d/%d", p.ProcessedItems, p.TotalItems)
					break
				}
			}
		}
	}

	// Create new progress if not resuming
	if progress == nil {
		progress, err = uc.progressService.StartOperation(ctx, entities.OperationFileScan, 0)
		if err != nil {
			return nil, fmt.Errorf("ì§„í–‰ ìƒí™© ìƒì„± ì‹¤íŒ¨: %w", err)
		}
	}

	// Initialize response
	response := &ScanAllFilesResponse{
		Progress: progress,
		Errors:   make([]string, 0),
	}

	// Start scanning in background with a new context (not tied to HTTP request)
	go uc.performFullScan(context.Background(), progress, req.ProgressCallback, response)

	return response, nil
}

// ScanFolder scans files in a specific folder
func (uc *FileScanningUseCase) ScanFolder(ctx context.Context, req *ScanFolderRequest) (*ScanFolderResponse, error) {
	log.Printf("ğŸ“ í´ë” ìŠ¤ìº” ì‹œì‘: %s", req.FolderID)

	// Validate folder access
	if err := uc.fileService.ValidateFileAccess(ctx, req.FolderID); err != nil {
		return nil, fmt.Errorf("í´ë” ì ‘ê·¼ ê¶Œí•œ í™•ì¸ ì‹¤íŒ¨: %w", err)
	}

	// Create progress tracker
	progress, err := uc.progressService.StartOperation(ctx, entities.OperationFileScan, 0)
	if err != nil {
		return nil, fmt.Errorf("ì§„í–‰ ìƒí™© ìƒì„± ì‹¤íŒ¨: %w", err)
	}

	// Get folder path
	folderPath, err := uc.storageProvider.GetFolderPath(ctx, req.FolderID)
	if err != nil {
		log.Printf("âš ï¸ í´ë” ê²½ë¡œ ì¡°íšŒ ì‹¤íŒ¨: %v", err)
		folderPath = "ì•Œ ìˆ˜ ì—†ëŠ” ê²½ë¡œ"
	}

	// Initialize response
	response := &ScanFolderResponse{
		Progress:   progress,
		FolderPath: folderPath,
		Errors:     make([]string, 0),
	}

	// Start scanning in background with a new context (not tied to HTTP request)
	go uc.performFolderScan(context.Background(), req.FolderID, req.Recursive, req.UpdatePaths, progress, req.ProgressCallback, response)

	return response, nil
}

// performFullScan performs the actual full file scanning
func (uc *FileScanningUseCase) performFullScan(ctx context.Context, progress *entities.Progress, callback func(*entities.Progress), response *ScanAllFilesResponse) {
	defer func() {
		if r := recover(); r != nil {
			log.Printf("âŒ ì „ì²´ ìŠ¤ìº” ì¤‘ íŒ¨ë‹‰ ë°œìƒ: %v", r)
			uc.progressService.FailOperation(ctx, progress.ID, fmt.Sprintf("íŒ¨ë‹‰ ë°œìƒ: %v", r))
		}
	}()

	// Update progress to running
	progress.Start()
	uc.progressService.UpdateOperation(ctx, progress.ID, 0, "íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì¤‘...")

	// Get all files from storage
	files, err := uc.storageProvider.ListAllFiles(ctx)
	if err != nil {
		log.Printf("âŒ íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: %v", err)
		uc.progressService.FailOperation(ctx, progress.ID, fmt.Sprintf("íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: %v", err))
		return
	}

	// Update total count
	progress.SetTotal(len(files))
	response.TotalFiles = len(files)

	log.Printf("ğŸ“Š ì´ %dê°œ íŒŒì¼ ë°œê²¬", len(files))

	// Process files in batches
	log.Printf("ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: %dê°œ íŒŒì¼ì„ %dê°œì”© ì²˜ë¦¬", len(files), uc.batchSize)
	uc.processBatches(ctx, files, progress, callback, response)

	// Complete the operation
	log.Printf("ğŸ ìŠ¤ìº” ì™„ë£Œ ì²˜ë¦¬ ì‹œì‘: ì§„í–‰ ìƒí™© ID %d", progress.ID)
	
	// Update progress status to completed directly via repository
	progress.SetTotal(len(files))
	progress.Complete()
	err = uc.progressRepo.Update(ctx, progress)
	if err != nil {
		log.Printf("âš ï¸ ì§„í–‰ ìƒí™© ì™„ë£Œ ì²˜ë¦¬ ì‹¤íŒ¨: %v", err)
	} else {
		log.Printf("âœ… ì§„í–‰ ìƒí™© ì™„ë£Œ ì²˜ë¦¬ ì„±ê³µ - DB ì§ì ‘ ì—…ë°ì´íŠ¸")
	}
	log.Printf("ğŸ“Š ìµœì¢… ìƒíƒœ: ì²˜ë¦¬ëœ íŒŒì¼=%d, ìƒˆ íŒŒì¼=%d, ì—…ë°ì´íŠ¸ëœ íŒŒì¼=%d", 
		response.ProcessedFiles, response.NewFiles, response.UpdatedFiles)

	if callback != nil {
		callback(progress)
	}

	log.Printf("âœ… ì „ì²´ íŒŒì¼ ìŠ¤ìº” ì™„ë£Œ: %dê°œ íŒŒì¼ ì²˜ë¦¬", response.ProcessedFiles)
}

// performFolderScan performs the actual folder scanning
func (uc *FileScanningUseCase) performFolderScan(ctx context.Context, folderID string, recursive, updatePaths bool, progress *entities.Progress, callback func(*entities.Progress), response *ScanFolderResponse) {
	defer func() {
		if r := recover(); r != nil {
			log.Printf("âŒ í´ë” ìŠ¤ìº” ì¤‘ íŒ¨ë‹‰ ë°œìƒ: %v", r)
			uc.progressService.FailOperation(ctx, progress.ID, fmt.Sprintf("íŒ¨ë‹‰ ë°œìƒ: %v", r))
		}
	}()

	// Update progress to running
	progress.Start()
	uc.progressService.UpdateOperation(ctx, progress.ID, 0, "í´ë” íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì¤‘...")

	// Get files from folder
	var files []*entities.File
	var err error

	if recursive {
		files, err = uc.scanFolderRecursive(ctx, folderID)
	} else {
		files, err = uc.storageProvider.ListFiles(ctx, folderID)
	}

	if err != nil {
		log.Printf("âŒ í´ë” íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: %v", err)
		uc.progressService.FailOperation(ctx, progress.ID, fmt.Sprintf("í´ë” íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: %v", err))
		return
	}

	// Update total count
	progress.SetTotal(len(files))
	response.TotalFiles = len(files)

	log.Printf("ğŸ“Š í´ë” ë‚´ %dê°œ íŒŒì¼ ë°œê²¬", len(files))

	// Update paths if requested
	if updatePaths {
		uc.progressService.UpdateOperation(ctx, progress.ID, 0, "íŒŒì¼ ê²½ë¡œ ì—…ë°ì´íŠ¸ ì¤‘...")
		if err := uc.fileService.UpdateFilePaths(ctx, files); err != nil {
			log.Printf("âš ï¸ íŒŒì¼ ê²½ë¡œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: %v", err)
			response.Errors = append(response.Errors, fmt.Sprintf("íŒŒì¼ ê²½ë¡œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: %v", err))
		}
	}

	// Process files in batches
	uc.processBatches(ctx, files, progress, callback, &ScanAllFilesResponse{
		Progress:       response.Progress,
		TotalFiles:     response.TotalFiles,
		ProcessedFiles: response.ProcessedFiles,
		NewFiles:       response.NewFiles,
		UpdatedFiles:   response.UpdatedFiles,
		Errors:         response.Errors,
	})

	// Response is already updated through tempResponse

	// Complete the operation
	uc.progressService.CompleteOperation(ctx, progress.ID)
	progress.Complete()

	if callback != nil {
		callback(progress)
	}

	log.Printf("âœ… í´ë” ìŠ¤ìº” ì™„ë£Œ: %dê°œ íŒŒì¼ ì²˜ë¦¬", response.ProcessedFiles)
}

// processBatches processes files in batches
func (uc *FileScanningUseCase) processBatches(ctx context.Context, files []*entities.File, progress *entities.Progress, callback func(*entities.Progress), response *ScanAllFilesResponse) {
	totalFiles := len(files)
	log.Printf("ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ ì„¸ë¶€ì‚¬í•­: ì´ %dê°œ íŒŒì¼, ë°°ì¹˜ í¬ê¸° %d, ì›Œì»¤ %dê°œ", totalFiles, uc.batchSize, uc.workerCount)

	batchCount := 0
	for i := 0; i < totalFiles; i += uc.batchSize {
		end := i + uc.batchSize
		if end > totalFiles {
			end = totalFiles
		}

		batch := files[i:end]
		batchCount++
		
		log.Printf("ğŸ“¦ ë°°ì¹˜ %d ì²˜ë¦¬ ì‹œì‘: %d-%dë²ˆì§¸ íŒŒì¼ (%dê°œ)", batchCount, i+1, end, len(batch))

		// Process batch
		newFiles, updatedFiles, errors := uc.processBatch(ctx, batch)
		
		log.Printf("ğŸ“Š ë°°ì¹˜ %d ê²°ê³¼: ìƒˆ íŒŒì¼ %dê°œ, ì—…ë°ì´íŠ¸ %dê°œ, ì—ëŸ¬ %dê°œ", batchCount, newFiles, updatedFiles, len(errors))

		// Update response
		response.ProcessedFiles += len(batch)
		response.NewFiles += newFiles
		response.UpdatedFiles += updatedFiles
		response.Errors = append(response.Errors, errors...)

		// Update progress
		progress.UpdateProgress(response.ProcessedFiles, fmt.Sprintf("ë°°ì¹˜ %d/%d ì™„ë£Œ (%d/%d íŒŒì¼)", batchCount, (totalFiles+uc.batchSize-1)/uc.batchSize, response.ProcessedFiles, totalFiles))
		uc.progressService.UpdateOperation(ctx, progress.ID, response.ProcessedFiles, progress.CurrentStep)

		// Call progress callback
		if callback != nil {
			callback(progress)
		}

		// Log progress
		log.Printf("ğŸ“ˆ ì§„í–‰ ìƒí™©: %d/%d (%.1f%%) - ìƒˆ íŒŒì¼: %d, ì—…ë°ì´íŠ¸: %d", 
			response.ProcessedFiles, totalFiles, float64(response.ProcessedFiles)/float64(totalFiles)*100,
			response.NewFiles, response.UpdatedFiles)
	}
	
	log.Printf("ğŸ¯ ëª¨ë“  ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: %dê°œ ë°°ì¹˜ ì²˜ë¦¬ë¨", batchCount)
}

// processBatch processes a batch of files
func (uc *FileScanningUseCase) processBatch(ctx context.Context, batch []*entities.File) (newFiles, updatedFiles int, errors []string) {
	errors = make([]string, 0)

	// Use worker pool for parallel processing
	jobs := make(chan *entities.File, len(batch))
	results := make(chan struct {
		isNew bool
		err   error
	}, len(batch))

	// Start workers
	var wg sync.WaitGroup
	for w := 0; w < uc.workerCount; w++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for file := range jobs {
				isNew, err := uc.processFile(ctx, file)
				results <- struct {
					isNew bool
					err   error
				}{isNew: isNew, err: err}
			}
		}()
	}

	// Send jobs
	for _, file := range batch {
		jobs <- file
	}
	close(jobs)

	// Wait for workers to complete
	go func() {
		wg.Wait()
		close(results)
	}()

	// Collect results
	for result := range results {
		if result.err != nil {
			errors = append(errors, result.err.Error())
		} else if result.isNew {
			newFiles++
		} else {
			updatedFiles++
		}
	}

	return newFiles, updatedFiles, errors
}

// processFile processes a single file
func (uc *FileScanningUseCase) processFile(ctx context.Context, file *entities.File) (isNew bool, err error) {
	// Check if file exists
	exists, err := uc.fileRepo.Exists(ctx, file.ID)
	if err != nil {
		return false, fmt.Errorf("íŒŒì¼ ì¡´ì¬ í™•ì¸ ì‹¤íŒ¨ [%s]: %w", file.ID, err)
	}

	if exists {
		// Update existing file
		err = uc.fileRepo.Update(ctx, file)
		if err != nil {
			return false, fmt.Errorf("íŒŒì¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ [%s]: %w", file.ID, err)
		}
		return false, nil
	} else {
		// Save new file
		err = uc.fileRepo.Save(ctx, file)
		if err != nil {
			return false, fmt.Errorf("íŒŒì¼ ì €ì¥ ì‹¤íŒ¨ [%s]: %w", file.ID, err)
		}
		return true, nil
	}
}

// scanFolderRecursive recursively scans a folder and its subfolders
func (uc *FileScanningUseCase) scanFolderRecursive(ctx context.Context, folderID string) ([]*entities.File, error) {
	var allFiles []*entities.File

	// Get files in current folder
	files, err := uc.storageProvider.ListFiles(ctx, folderID)
	if err != nil {
		return nil, err
	}

	// Separate files and folders
	var actualFiles []*entities.File
	var subfolders []*entities.File

	for _, file := range files {
		if file.GetFileCategory() == "folder" {
			subfolders = append(subfolders, file)
		} else {
			actualFiles = append(actualFiles, file)
		}
	}

	// Add current folder files
	allFiles = append(allFiles, actualFiles...)

	// Recursively scan subfolders
	for _, subfolder := range subfolders {
		subFiles, err := uc.scanFolderRecursive(ctx, subfolder.ID)
		if err != nil {
			log.Printf("âš ï¸ í•˜ìœ„ í´ë” ìŠ¤ìº” ì‹¤íŒ¨ [%s]: %v", subfolder.ID, err)
			continue
		}
		allFiles = append(allFiles, subFiles...)
	}

	return allFiles, nil
}

// GetScanProgress returns the current scan progress
func (uc *FileScanningUseCase) GetScanProgress(ctx context.Context) (*entities.Progress, error) {
	activeProgress, err := uc.progressService.GetActiveOperations(ctx)
	if err != nil {
		return nil, err
	}

	for _, progress := range activeProgress {
		if progress.OperationType == entities.OperationFileScan {
			return progress, nil
		}
	}

	return nil, fmt.Errorf("í™œì„± íŒŒì¼ ìŠ¤ìº” ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
}

// SetConfiguration sets the use case configuration
func (uc *FileScanningUseCase) SetConfiguration(batchSize, workerCount int, saveInterval time.Duration) {
	if batchSize > 0 {
		uc.batchSize = batchSize
	}
	if workerCount > 0 {
		uc.workerCount = workerCount
	}
	if saveInterval > 0 {
		uc.saveInterval = saveInterval
	}
}

// ClearFailedProgress clears all failed or pending progress records
func (uc *FileScanningUseCase) ClearFailedProgress(ctx context.Context) error {
	log.Println("ğŸ§¹ ì‹¤íŒ¨í•œ ì§„í–‰ ìƒí™© ì •ë¦¬ ì‹œì‘")

	// Get all progress records
	allProgress, err := uc.progressService.GetActiveOperations(ctx)
	if err != nil {
		return fmt.Errorf("ì§„í–‰ ìƒí™© ì¡°íšŒ ì‹¤íŒ¨: %w", err)
	}

	clearedCount := 0
	for _, progress := range allProgress {
		// Clear records that are in failed, pending, or stuck states
		if progress.Status == "failed" || progress.Status == "pending" {
			// Clear all pending operations (ìˆ˜ë™ ì •ë¦¬ì´ë¯€ë¡œ ì‹œê°„ ì œí•œ ì—†ìŒ)
			// if progress.Status == "pending" && time.Since(progress.StartTime) < 10*time.Minute {
			//	continue // Skip recent pending operations
			// }

			err := uc.progressService.FailOperation(ctx, progress.ID, "ìˆ˜ë™ìœ¼ë¡œ ì •ë¦¬ë¨")
			if err != nil {
				log.Printf("âš ï¸ ì§„í–‰ ìƒí™© ì •ë¦¬ ì‹¤íŒ¨ [%d]: %v", progress.ID, err)
				continue
			}
			clearedCount++
			log.Printf("ğŸ—‘ï¸ ì§„í–‰ ìƒí™© ì •ë¦¬ë¨: ID=%d, Type=%s, Status=%s", 
				progress.ID, progress.OperationType, progress.Status)
		}
	}

	log.Printf("âœ… %dê°œ ì§„í–‰ ìƒí™© ì •ë¦¬ ì™„ë£Œ", clearedCount)
	return nil
}
