package main

import (
	"context"
	"crypto/sha256"
	"database/sql"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"math"
	"net/http"
	"os"
	"regexp"
	"strings"
	"sync"
	"time"

	_ "github.com/mattn/go-sqlite3"
	"golang.org/x/oauth2"
	"golang.org/x/oauth2/google"
	"google.golang.org/api/drive/v3"
	"google.golang.org/api/googleapi"
	"google.golang.org/api/option"
)

type DriveFile struct {
	ID           string   `json:"id"`
	Name         string   `json:"name"`
	Size         int64    `json:"size"`
	WebViewLink  string   `json:"webViewLink"`
	MimeType     string   `json:"mimeType"`
	ModifiedTime string   `json:"modifiedTime"`
	Hash         string   `json:"hash,omitempty"`
	Parents      []string `json:"parents,omitempty"`
	Path         string   `json:"path,omitempty"`
}

type DriveService struct {
	service *drive.Service
	db      *sql.DB
}

type ProgressData struct {
	ProcessedFiles int                     `json:"processedFiles"`
	TotalFiles     int                     `json:"totalFiles"`
	CompletedGroups int                    `json:"completedGroups"`
	CurrentGroup   int                     `json:"currentGroup"`
	Duplicates     [][]*DriveFile          `json:"duplicates"`
	LastUpdated    time.Time               `json:"lastUpdated"`
	Status         string                  `json:"status"` // "running", "paused", "completed"
	LastPageToken  string                  `json:"lastPageToken,omitempty"`
	LastPageCount  int                     `json:"lastPageCount"`
}

const (
	dbFile = "drive_duplicates.db"
)

func initDB() (*sql.DB, error) {
	log.Println("ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
	db, err := sql.Open("sqlite3", dbFile)
	if err != nil {
		return nil, fmt.Errorf("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: %v", err)
	}

	// íŒŒì¼ í…Œì´ë¸” ìƒì„±
	_, err = db.Exec(`
		CREATE TABLE IF NOT EXISTS files (
			id TEXT PRIMARY KEY,
			name TEXT NOT NULL,
			size INTEGER NOT NULL,
			web_view_link TEXT NOT NULL,
			mime_type TEXT NOT NULL,
			modified_time TEXT NOT NULL,
			hash TEXT DEFAULT '',
			hash_calculated BOOLEAN DEFAULT FALSE,
			parents TEXT DEFAULT '',
			path TEXT DEFAULT '',
			last_updated DATETIME DEFAULT CURRENT_TIMESTAMP
		)
	`)
	if err != nil {
		return nil, fmt.Errorf("files í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: %v", err)
	}

	// ì§„í–‰ ìƒíƒœ í…Œì´ë¸” ìƒì„±
	_, err = db.Exec(`
		CREATE TABLE IF NOT EXISTS progress (
			id INTEGER PRIMARY KEY,
			processed_files INTEGER DEFAULT 0,
			total_files INTEGER DEFAULT 0,
			completed_groups INTEGER DEFAULT 0,
			current_group INTEGER DEFAULT 0,
			status TEXT DEFAULT 'idle',
			last_page_token TEXT DEFAULT '',
			last_page_count INTEGER DEFAULT 0,
			last_updated DATETIME DEFAULT CURRENT_TIMESTAMP
		)
	`)
	if err != nil {
		return nil, fmt.Errorf("progress í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: %v", err)
	}

	// í´ë” ë¹„êµ ì‘ì—… í…Œì´ë¸” ìƒì„±
	_, err = db.Exec(`
		CREATE TABLE IF NOT EXISTS folder_comparison_tasks (
			id INTEGER PRIMARY KEY,
			source_folder_id TEXT NOT NULL,
			target_folder_id TEXT NOT NULL,
			status TEXT DEFAULT 'pending',
			current_step TEXT DEFAULT '',
			source_folder_scanned INTEGER DEFAULT 0,
			source_folder_total INTEGER DEFAULT 0,
			target_folder_scanned INTEGER DEFAULT 0,
			target_folder_total INTEGER DEFAULT 0,
			hashes_calculated INTEGER DEFAULT 0,
			total_hashes_to_calc INTEGER DEFAULT 0,
			duplicates_found INTEGER DEFAULT 0,
			error_message TEXT DEFAULT '',
			created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
			updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
		)
	`)
	if err != nil {
		return nil, fmt.Errorf("folder_comparison_tasks í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: %v", err)
	}

	// í´ë” ë¹„êµ ê²°ê³¼ íŒŒì¼ ì €ì¥ í…Œì´ë¸”
	_, err = db.Exec(`
		CREATE TABLE IF NOT EXISTS comparison_result_files (
			id INTEGER PRIMARY KEY,
			task_id INTEGER NOT NULL,
			file_id TEXT NOT NULL,
			file_name TEXT NOT NULL,
			file_size INTEGER NOT NULL,
			file_hash TEXT NOT NULL,
			file_path TEXT DEFAULT '',
			web_view_link TEXT DEFAULT '',
			mime_type TEXT DEFAULT '',
			modified_time TEXT DEFAULT '',
			is_duplicate BOOLEAN DEFAULT FALSE,
			folder_type TEXT NOT NULL, -- 'source' or 'target'
			FOREIGN KEY (task_id) REFERENCES folder_comparison_tasks (id)
		)
	`)
	if err != nil {
		return nil, fmt.Errorf("progress í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: %v", err)
	}

	// ì„¤ì • í…Œì´ë¸” ìƒì„±
	_, err = db.Exec(`
		CREATE TABLE IF NOT EXISTS settings (
			key TEXT PRIMARY KEY,
			value TEXT NOT NULL,
			updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
		)
	`)
	if err != nil {
		return nil, fmt.Errorf("settings í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: %v", err)
	}

	// ê¸°ë³¸ ë³‘ë ¬ ì‘ì—… ê°œìˆ˜ ì„¤ì •
	_, err = db.Exec(`
		INSERT OR IGNORE INTO settings (key, value) VALUES ('max_workers', '3')
	`)
	if err != nil {
		return nil, fmt.Errorf("ê¸°ë³¸ ì„¤ì • ì¶”ê°€ ì˜¤ë¥˜: %v", err)
	}

	// ì¤‘ë³µ ê·¸ë£¹ í…Œì´ë¸” ìƒì„±
	_, err = db.Exec(`
		CREATE TABLE IF NOT EXISTS duplicate_groups (
			id INTEGER PRIMARY KEY AUTOINCREMENT,
			hash TEXT NOT NULL,
			group_size INTEGER NOT NULL,
			created_at DATETIME DEFAULT CURRENT_TIMESTAMP
		)
	`)
	if err != nil {
		return nil, fmt.Errorf("duplicate_groups í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: %v", err)
	}

	// ì¤‘ë³µ íŒŒì¼ ë§¤í•‘ í…Œì´ë¸” ìƒì„±
	_, err = db.Exec(`
		CREATE TABLE IF NOT EXISTS duplicate_files (
			group_id INTEGER,
			file_id TEXT,
			FOREIGN KEY (group_id) REFERENCES duplicate_groups(id),
			FOREIGN KEY (file_id) REFERENCES files(id)
		)
	`)
	if err != nil {
		return nil, fmt.Errorf("duplicate_files í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: %v", err)
	}

	// ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
	err = migrateDatabaseSchema(db)
	if err != nil {
		return nil, fmt.Errorf("ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜¤ë¥˜: %v", err)
	}

	log.Println("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
	return db, nil
}

func migrateDatabaseSchema(db *sql.DB) error {
	log.Println("ğŸ”„ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...")
	
	// files í…Œì´ë¸”ì— parents, path ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
	rows, err := db.Query("PRAGMA table_info(files)")
	if err != nil {
		return fmt.Errorf("í…Œì´ë¸” ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: %v", err)
	}
	defer rows.Close()
	
	hasParents := false
	hasPath := false
	
	for rows.Next() {
		var cid int
		var name, dataType string
		var notNull, dfltValue, pk interface{}
		
		err := rows.Scan(&cid, &name, &dataType, &notNull, &dfltValue, &pk)
		if err != nil {
			continue
		}
		
		if name == "parents" {
			hasParents = true
		}
		if name == "path" {
			hasPath = true
		}
	}
	
	// parents ì»¬ëŸ¼ ì¶”ê°€
	if !hasParents {
		log.Println("ğŸ“ parents ì»¬ëŸ¼ ì¶”ê°€ ì¤‘...")
		_, err = db.Exec("ALTER TABLE files ADD COLUMN parents TEXT DEFAULT ''")
		if err != nil {
			return fmt.Errorf("parents ì»¬ëŸ¼ ì¶”ê°€ ì˜¤ë¥˜: %v", err)
		}
		log.Println("âœ… parents ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")
	}
	
	// path ì»¬ëŸ¼ ì¶”ê°€
	if !hasPath {
		log.Println("ğŸ“ path ì»¬ëŸ¼ ì¶”ê°€ ì¤‘...")
		_, err = db.Exec("ALTER TABLE files ADD COLUMN path TEXT DEFAULT ''")
		if err != nil {
			return fmt.Errorf("path ì»¬ëŸ¼ ì¶”ê°€ ì˜¤ë¥˜: %v", err)
		}
		log.Println("âœ… path ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")
	}
	
	// progress í…Œì´ë¸”ì— ìƒˆ ì»¬ëŸ¼ ì¶”ê°€
	err = migrateProgressTable(db)
	if err != nil {
		return fmt.Errorf("progress í…Œì´ë¸” ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜¤ë¥˜: %v", err)
	}
	
	log.Println("âœ… ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
	return nil
}

func migrateProgressTable(db *sql.DB) error {
	// progress í…Œì´ë¸” êµ¬ì¡° í™•ì¸
	rows, err := db.Query("PRAGMA table_info(progress)")
	if err != nil {
		return fmt.Errorf("progress í…Œì´ë¸” ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: %v", err)
	}
	defer rows.Close()
	
	hasLastPageToken := false
	hasLastPageCount := false
	
	for rows.Next() {
		var cid int
		var name, dataType string
		var notNull, dfltValue, pk interface{}
		
		err := rows.Scan(&cid, &name, &dataType, &notNull, &dfltValue, &pk)
		if err != nil {
			continue
		}
		
		if name == "last_page_token" {
			hasLastPageToken = true
		}
		if name == "last_page_count" {
			hasLastPageCount = true
		}
	}
	
	// last_page_token ì»¬ëŸ¼ ì¶”ê°€
	if !hasLastPageToken {
		log.Println("ğŸ“ progress í…Œì´ë¸”ì— last_page_token ì»¬ëŸ¼ ì¶”ê°€ ì¤‘...")
		_, err = db.Exec("ALTER TABLE progress ADD COLUMN last_page_token TEXT DEFAULT ''")
		if err != nil {
			return fmt.Errorf("last_page_token ì»¬ëŸ¼ ì¶”ê°€ ì˜¤ë¥˜: %v", err)
		}
		log.Println("âœ… last_page_token ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")
	}
	
	// last_page_count ì»¬ëŸ¼ ì¶”ê°€
	if !hasLastPageCount {
		log.Println("ğŸ“ progress í…Œì´ë¸”ì— last_page_count ì»¬ëŸ¼ ì¶”ê°€ ì¤‘...")
		_, err = db.Exec("ALTER TABLE progress ADD COLUMN last_page_count INTEGER DEFAULT 0")
		if err != nil {
			return fmt.Errorf("last_page_count ì»¬ëŸ¼ ì¶”ê°€ ì˜¤ë¥˜: %v", err)
		}
		log.Println("âœ… last_page_count ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")
	}
	
	return nil
}

func NewDriveService(ctx context.Context) (*DriveService, error) {
	log.Println("ğŸ”§ OAuth ì„¤ì • íŒŒì¼ ì½ëŠ” ì¤‘...")
	config, err := getOAuthConfig()
	if err != nil {
		return nil, fmt.Errorf("OAuth ì„¤ì • ì˜¤ë¥˜: %v", err)
	}
	log.Println("âœ… OAuth ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ")

	log.Println("ğŸ« ì•¡ì„¸ìŠ¤ í† í° í™•ì¸ ì¤‘...")
	token, err := getToken(config)
	if err != nil {
		return nil, fmt.Errorf("í† í° íšë“ ì˜¤ë¥˜: %v", err)
	}
	log.Println("âœ… ì•¡ì„¸ìŠ¤ í† í° í™•ì¸ ì™„ë£Œ")

	log.Println("ğŸŒ Google Drive ì„œë¹„ìŠ¤ ì—°ê²° ì¤‘...")
	client := config.Client(ctx, token)
	
	// HTTP í´ë¼ì´ì–¸íŠ¸ ìµœì í™” (ì„±ëŠ¥ í–¥ìƒ)
	optimizedClient := optimizeHTTPClient(client)
	
	service, err := drive.NewService(ctx, option.WithHTTPClient(optimizedClient))
	if err != nil {
		return nil, fmt.Errorf("Drive ì„œë¹„ìŠ¤ ìƒì„± ì˜¤ë¥˜: %v", err)
	}
	log.Println("âœ… Google Drive ì„œë¹„ìŠ¤ ì—°ê²° ì„±ê³µ")

	// DB ì´ˆê¸°í™”
	db, err := initDB()
	if err != nil {
		return nil, err
	}

	return &DriveService{service: service, db: db}, nil
}

// HTTP í´ë¼ì´ì–¸íŠ¸ ì„±ëŠ¥ ìµœì í™”
func optimizeHTTPClient(client *http.Client) *http.Client {
	// ê¸°ì¡´ Transportë¥¼ ë³µì œí•˜ì—¬ ì„¤ì • ìœ ì§€
	var baseTransport *http.Transport
	if client.Transport != nil {
		if transport, ok := client.Transport.(*http.Transport); ok {
			baseTransport = transport.Clone()
		} else if transport, ok := client.Transport.(*oauth2.Transport); ok {
			if innerTransport, ok := transport.Base.(*http.Transport); ok {
				baseTransport = innerTransport.Clone()
			}
		}
	}
	
	// ê¸°ë³¸ Transport ì„¤ì • (ë°±ì—…)
	if baseTransport == nil {
		baseTransport = http.DefaultTransport.(*http.Transport).Clone()
	}
	
	// ê¸°ë³¸ ì—°ê²° ì„¤ì • (íƒ€ì„ì•„ì›ƒ ì œê±°)
	baseTransport.MaxIdleConns = 100          // ìµœëŒ€ ìœ íœ´ ì—°ê²° ìˆ˜
	baseTransport.MaxIdleConnsPerHost = 20    // í˜¸ìŠ¤íŠ¸ë‹¹ ìµœëŒ€ ìœ íœ´ ì—°ê²° ìˆ˜
	baseTransport.MaxConnsPerHost = 50        // í˜¸ìŠ¤íŠ¸ë‹¹ ìµœëŒ€ ì—°ê²° ìˆ˜
	// ëª¨ë“  íƒ€ì„ì•„ì›ƒ ì„¤ì • ì œê±°
	
	// ì••ì¶• í™œì„±í™”
	baseTransport.DisableCompression = false
	
	// OAuth Transport ë˜í•‘ ìœ ì§€
	var finalTransport http.RoundTripper = baseTransport
	if oauthTransport, ok := client.Transport.(*oauth2.Transport); ok {
		oauthTransport.Base = baseTransport
		finalTransport = oauthTransport
	}
	
	optimizedClient := &http.Client{
		Transport: finalTransport,
		// Timeout ì œê±° - ë¬´ì œí•œ ëŒ€ê¸°
	}
	
	log.Printf("ğŸš€ HTTP í´ë¼ì´ì–¸íŠ¸ ìµœì í™” ì ìš©: MaxConns=%d, MaxIdleConns=%d, Timeout=ë¬´ì œí•œ", 
		baseTransport.MaxConnsPerHost, baseTransport.MaxIdleConns)
	
	return optimizedClient
}

func getOAuthConfig() (*oauth2.Config, error) {
	credentialsFile := "credentials.json"
	
	b, err := os.ReadFile(credentialsFile)
	if err != nil {
		return nil, fmt.Errorf("credentials.json íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: %v\nêµ¬ê¸€ í´ë¼ìš°ë“œ ì½˜ì†”ì—ì„œ OAuth 2.0 í´ë¼ì´ì–¸íŠ¸ IDë¥¼ ìƒì„±í•˜ê³  credentials.jsonìœ¼ë¡œ ì €ì¥í•˜ì„¸ìš”", err)
	}

	config, err := google.ConfigFromJSON(b, drive.DriveScope)
	if err != nil {
		return nil, fmt.Errorf("OAuth ì„¤ì • íŒŒì‹± ì˜¤ë¥˜: %v", err)
	}

	// ë°ìŠ¤í¬í†± ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ê²½ìš° redirect URL ì„¤ì •
	if config.RedirectURL == "" {
		config.RedirectURL = "urn:ietf:wg:oauth:2.0:oob"
	}

	return config, nil
}

func getToken(config *oauth2.Config) (*oauth2.Token, error) {
	tokenFile := "token.json"
	
	token, err := tokenFromFile(tokenFile)
	if err != nil {
		token = getTokenFromWeb(config)
		saveToken(tokenFile, token)
	}
	
	return token, nil
}

func getTokenFromWeb(config *oauth2.Config) *oauth2.Token {
	authURL := config.AuthCodeURL("state-token", oauth2.AccessTypeOffline)
	log.Println("ğŸ” Google ê³„ì • ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤!")
	log.Println("ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¼ì£¼ì„¸ìš”:")
	log.Println("1. ì•„ë˜ ë§í¬ë¥¼ ë³µì‚¬í•˜ì—¬ ë¸Œë¼ìš°ì €ì—ì„œ ì—´ê¸°")
	log.Println("2. Google ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸")
	log.Println("3. ê¶Œí•œ í—ˆìš©")
	log.Println("4. í‘œì‹œë˜ëŠ” ì¸ì¦ ì½”ë“œë¥¼ ë³µì‚¬")
	log.Println("5. ì•„ë˜ì— ì¸ì¦ ì½”ë“œ ì…ë ¥")
	log.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Printf("%v\n", authURL)
	log.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Print("ì¸ì¦ ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")

	var authCode string
	if _, err := fmt.Scan(&authCode); err != nil {
		log.Fatalf("âŒ ì¸ì¦ ì½”ë“œ ì…ë ¥ ì˜¤ë¥˜: %v", err)
	}

	log.Println("ğŸ”„ ì¸ì¦ ì½”ë“œë¥¼ í† í°ìœ¼ë¡œ êµí™˜ ì¤‘...")
	token, err := config.Exchange(context.TODO(), authCode)
	if err != nil {
		log.Fatalf("âŒ í† í° êµí™˜ ì˜¤ë¥˜: %v", err)
	}
	
	log.Println("âœ… ì¸ì¦ ì„±ê³µ! í† í°ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
	return token
}

func tokenFromFile(file string) (*oauth2.Token, error) {
	f, err := os.Open(file)
	if err != nil {
		return nil, err
	}
	defer f.Close()
	
	token := &oauth2.Token{}
	err = json.NewDecoder(f).Decode(token)
	
	return token, err
}

func saveToken(path string, token *oauth2.Token) {
	f, err := os.OpenFile(path, os.O_RDWR|os.O_CREATE|os.O_TRUNC, 0600)
	if err != nil {
		log.Fatalf("í† í° íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: %v", err)
	}
	defer f.Close()
	
	json.NewEncoder(f).Encode(token)
}

func (ds *DriveService) saveFilesToDB(files []*DriveFile) error {
	log.Println("ğŸ—„ï¸ íŒŒì¼ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì¤‘...")
	
	tx, err := ds.db.Begin()
	if err != nil {
		return fmt.Errorf("íŠ¸ëœì­ì…˜ ì‹œì‘ ì˜¤ë¥˜: %v", err)
	}
	defer tx.Rollback()

	// í…Œì´ë¸” êµ¬ì¡° í™•ì¸
	rows, err := tx.Query("PRAGMA table_info(files)")
	if err != nil {
		return fmt.Errorf("í…Œì´ë¸” ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: %v", err)
	}
	
	hasParents := false
	hasPath := false
	
	for rows.Next() {
		var cid int
		var name, dataType string
		var notNull, dfltValue, pk interface{}
		
		err := rows.Scan(&cid, &name, &dataType, &notNull, &dfltValue, &pk)
		if err != nil {
			continue
		}
		
		if name == "parents" {
			hasParents = true
		}
		if name == "path" {
			hasPath = true
		}
	}
	rows.Close()

	// ì»¬ëŸ¼ ìœ ë¬´ì— ë”°ë¼ ë‹¤ë¥¸ INSERT ë¬¸ ì‚¬ìš©
	var stmt *sql.Stmt
	if hasParents && hasPath {
		stmt, err = tx.Prepare(`
			INSERT OR REPLACE INTO files 
			(id, name, size, web_view_link, mime_type, modified_time, parents, path, last_updated)
			VALUES (?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
		`)
	} else {
		stmt, err = tx.Prepare(`
			INSERT OR REPLACE INTO files 
			(id, name, size, web_view_link, mime_type, modified_time, last_updated)
			VALUES (?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
		`)
	}
	
	if err != nil {
		return fmt.Errorf("ì¤€ë¹„ëœ ë¬¸ì¥ ìƒì„± ì˜¤ë¥˜: %v", err)
	}
	defer stmt.Close()

	for _, file := range files {
		if hasParents && hasPath {
			parentsJSON, _ := json.Marshal(file.Parents)
			_, err = stmt.Exec(file.ID, file.Name, file.Size, file.WebViewLink, file.MimeType, file.ModifiedTime, string(parentsJSON), file.Path)
		} else {
			_, err = stmt.Exec(file.ID, file.Name, file.Size, file.WebViewLink, file.MimeType, file.ModifiedTime)
		}
		
		if err != nil {
			return fmt.Errorf("íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: %v", err)
		}
	}

	if err = tx.Commit(); err != nil {
		return fmt.Errorf("íŠ¸ëœì­ì…˜ ì»¤ë°‹ ì˜¤ë¥˜: %v", err)
	}

	log.Printf("âœ… %dê°œ íŒŒì¼ ì •ë³´ê°€ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë¨", len(files))
	return nil
}

func (ds *DriveService) loadFilesFromDB() ([]*DriveFile, error) {
	log.Println("ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ íŒŒì¼ ëª©ë¡ ë¡œë“œ ì¤‘...")
	
	// í…Œì´ë¸” êµ¬ì¡° í™•ì¸
	infoRows, err := ds.db.Query("PRAGMA table_info(files)")
	if err != nil {
		return nil, fmt.Errorf("í…Œì´ë¸” ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: %v", err)
	}
	
	hasParents := false
	hasPath := false
	
	for infoRows.Next() {
		var cid int
		var name, dataType string
		var notNull, dfltValue, pk interface{}
		
		err := infoRows.Scan(&cid, &name, &dataType, &notNull, &dfltValue, &pk)
		if err != nil {
			continue
		}
		
		if name == "parents" {
			hasParents = true
		}
		if name == "path" {
			hasPath = true
		}
	}
	infoRows.Close()

	// ì»¬ëŸ¼ ìœ ë¬´ì— ë”°ë¼ ë‹¤ë¥¸ SELECT ë¬¸ ì‚¬ìš©
	var query string
	if hasParents && hasPath {
		query = `
			SELECT id, name, size, web_view_link, mime_type, modified_time, hash, hash_calculated, parents, path
			FROM files
			ORDER BY size DESC
		`
	} else {
		query = `
			SELECT id, name, size, web_view_link, mime_type, modified_time, hash, hash_calculated
			FROM files
			ORDER BY size DESC
		`
	}
	
	rows, err := ds.db.Query(query)
	if err != nil {
		return nil, fmt.Errorf("íŒŒì¼ ì¡°íšŒ ì˜¤ë¥˜: %v", err)
	}
	defer rows.Close()

	var files []*DriveFile
	for rows.Next() {
		file := &DriveFile{}
		var hashCalculated bool
		
		if hasParents && hasPath {
			var parentsJSON string
			err := rows.Scan(&file.ID, &file.Name, &file.Size, &file.WebViewLink, 
							&file.MimeType, &file.ModifiedTime, &file.Hash, &hashCalculated, &parentsJSON, &file.Path)
			if err != nil {
				return nil, fmt.Errorf("íŒŒì¼ ìŠ¤ìº” ì˜¤ë¥˜: %v", err)
			}
			
			// Parents JSONì„ íŒŒì‹±
			if parentsJSON != "" {
				json.Unmarshal([]byte(parentsJSON), &file.Parents)
			}
		} else {
			err := rows.Scan(&file.ID, &file.Name, &file.Size, &file.WebViewLink, 
							&file.MimeType, &file.ModifiedTime, &file.Hash, &hashCalculated)
			if err != nil {
				return nil, fmt.Errorf("íŒŒì¼ ìŠ¤ìº” ì˜¤ë¥˜: %v", err)
			}
			file.Path = ""
			file.Parents = []string{}
		}
		
		files = append(files, file)
	}

	if len(files) > 0 {
		log.Printf("âœ… ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ %dê°œ íŒŒì¼ ë¡œë“œ ì™„ë£Œ", len(files))
	}
	return files, nil
}

func (ds *DriveService) updateFileHash(fileID, hash string) error {
	_, err := ds.db.Exec(`
		UPDATE files 
		SET hash = ?, hash_calculated = TRUE, last_updated = CURRENT_TIMESTAMP
		WHERE id = ?
	`, hash, fileID)
	return err
}

func (ds *DriveService) saveProgress(progress ProgressData) error {
	// í…Œì´ë¸” êµ¬ì¡° í™•ì¸
	rows, err := ds.db.Query("PRAGMA table_info(progress)")
	if err != nil {
		return fmt.Errorf("progress í…Œì´ë¸” ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: %v", err)
	}
	
	hasLastPageToken := false
	hasLastPageCount := false
	
	for rows.Next() {
		var cid int
		var name, dataType string
		var notNull, dfltValue, pk interface{}
		
		err := rows.Scan(&cid, &name, &dataType, &notNull, &dfltValue, &pk)
		if err != nil {
			continue
		}
		
		if name == "last_page_token" {
			hasLastPageToken = true
		}
		if name == "last_page_count" {
			hasLastPageCount = true
		}
	}
	rows.Close()
	
	// ì»¬ëŸ¼ ìœ ë¬´ì— ë”°ë¼ ë‹¤ë¥¸ INSERT ë¬¸ ì‚¬ìš©
	if hasLastPageToken && hasLastPageCount {
		_, err = ds.db.Exec(`
			INSERT OR REPLACE INTO progress (id, processed_files, total_files, completed_groups, current_group, status, last_page_token, last_page_count, last_updated)
			VALUES (1, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
		`, progress.ProcessedFiles, progress.TotalFiles, progress.CompletedGroups, progress.CurrentGroup, progress.Status, progress.LastPageToken, progress.LastPageCount)
	} else {
		_, err = ds.db.Exec(`
			INSERT OR REPLACE INTO progress (id, processed_files, total_files, completed_groups, current_group, status, last_updated)
			VALUES (1, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
		`, progress.ProcessedFiles, progress.TotalFiles, progress.CompletedGroups, progress.CurrentGroup, progress.Status)
	}
	
	return err
}

func (ds *DriveService) loadProgress() (*ProgressData, error) {
	// í…Œì´ë¸” êµ¬ì¡° í™•ì¸
	rows, err := ds.db.Query("PRAGMA table_info(progress)")
	if err != nil {
		return nil, fmt.Errorf("progress í…Œì´ë¸” ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: %v", err)
	}
	
	hasLastPageToken := false
	hasLastPageCount := false
	
	for rows.Next() {
		var cid int
		var name, dataType string
		var notNull, dfltValue, pk interface{}
		
		err := rows.Scan(&cid, &name, &dataType, &notNull, &dfltValue, &pk)
		if err != nil {
			continue
		}
		
		if name == "last_page_token" {
			hasLastPageToken = true
		}
		if name == "last_page_count" {
			hasLastPageCount = true
		}
	}
	rows.Close()
	
	var progress ProgressData
	
	// ì»¬ëŸ¼ ìœ ë¬´ì— ë”°ë¼ ë‹¤ë¥¸ SELECT ë¬¸ ì‚¬ìš©
	if hasLastPageToken && hasLastPageCount {
		err = ds.db.QueryRow(`
			SELECT processed_files, total_files, completed_groups, current_group, status, last_page_token, last_page_count, last_updated
			FROM progress WHERE id = 1
		`).Scan(&progress.ProcessedFiles, &progress.TotalFiles, &progress.CompletedGroups, 
				&progress.CurrentGroup, &progress.Status, &progress.LastPageToken, &progress.LastPageCount, &progress.LastUpdated)
	} else {
		err = ds.db.QueryRow(`
			SELECT processed_files, total_files, completed_groups, current_group, status, last_updated
			FROM progress WHERE id = 1
		`).Scan(&progress.ProcessedFiles, &progress.TotalFiles, &progress.CompletedGroups, 
				&progress.CurrentGroup, &progress.Status, &progress.LastUpdated)
		
		// ê¸°ë³¸ê°’ ì„¤ì •
		progress.LastPageToken = ""
		progress.LastPageCount = 0
	}
	
	if err == sql.ErrNoRows {
		return &ProgressData{Status: "idle"}, nil
	}
	return &progress, err
}

func (ds *DriveService) saveSingleDuplicateGroup(group []*DriveFile) error {
	if len(group) < 2 {
		return nil
	}

	log.Printf("ğŸ’¾ ì¤‘ë³µ ê·¸ë£¹ ì €ì¥ ì¤‘: %dê°œ íŒŒì¼, í•´ì‹œ: %s...", len(group), group[0].Hash[:8])

	tx, err := ds.db.Begin()
	if err != nil {
		return fmt.Errorf("íŠ¸ëœì­ì…˜ ì‹œì‘ ì˜¤ë¥˜: %v", err)
	}
	defer tx.Rollback()

	// ë™ì¼í•œ í•´ì‹œì˜ ê¸°ì¡´ ê·¸ë£¹ì´ ìˆëŠ”ì§€ í™•ì¸
	var existingGroupID int64
	err = tx.QueryRow("SELECT id FROM duplicate_groups WHERE hash = ?", group[0].Hash).Scan(&existingGroupID)
	
	if err == sql.ErrNoRows {
		// ìƒˆ ê·¸ë£¹ ìƒì„±
		log.Printf("ğŸ†• ìƒˆ ì¤‘ë³µ ê·¸ë£¹ ìƒì„±: í•´ì‹œ %s...", group[0].Hash[:8])
		result, err := tx.Exec(`
			INSERT INTO duplicate_groups (hash, group_size)
			VALUES (?, ?)
		`, group[0].Hash, len(group))
		if err != nil {
			return fmt.Errorf("ê·¸ë£¹ ìƒì„± ì˜¤ë¥˜: %v", err)
		}

		existingGroupID, err = result.LastInsertId()
		if err != nil {
			return fmt.Errorf("ê·¸ë£¹ ID ì¡°íšŒ ì˜¤ë¥˜: %v", err)
		}
		log.Printf("âœ… ìƒˆ ê·¸ë£¹ ID: %d", existingGroupID)
	} else if err != nil {
		return fmt.Errorf("ê¸°ì¡´ ê·¸ë£¹ í™•ì¸ ì˜¤ë¥˜: %v", err)
	} else {
		// ê¸°ì¡´ ê·¸ë£¹ì˜ íŒŒì¼ë“¤ ì‚­ì œ í›„ ìƒˆë¡œ ì¶”ê°€
		log.Printf("ğŸ”„ ê¸°ì¡´ ê·¸ë£¹ ì—…ë°ì´íŠ¸: ID %d", existingGroupID)
		_, err = tx.Exec("DELETE FROM duplicate_files WHERE group_id = ?", existingGroupID)
		if err != nil {
			return fmt.Errorf("ê¸°ì¡´ íŒŒì¼ ì‚­ì œ ì˜¤ë¥˜: %v", err)
		}
		
		// ê·¸ë£¹ í¬ê¸° ì—…ë°ì´íŠ¸
		_, err = tx.Exec("UPDATE duplicate_groups SET group_size = ? WHERE id = ?", len(group), existingGroupID)
		if err != nil {
			return fmt.Errorf("ê·¸ë£¹ í¬ê¸° ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: %v", err)
		}
	}

	// ê·¸ë£¹ì— íŒŒì¼ë“¤ ì¶”ê°€
	for _, file := range group {
		_, err = tx.Exec(`
			INSERT INTO duplicate_files (group_id, file_id)
			VALUES (?, ?)
		`, existingGroupID, file.ID)
		if err != nil {
			return fmt.Errorf("íŒŒì¼ ì¶”ê°€ ì˜¤ë¥˜: %v", err)
		}
	}

	if err = tx.Commit(); err != nil {
		return fmt.Errorf("íŠ¸ëœì­ì…˜ ì»¤ë°‹ ì˜¤ë¥˜: %v", err)
	}

	log.Printf("âœ… ì¤‘ë³µ ê·¸ë£¹ ì €ì¥ ì™„ë£Œ: ê·¸ë£¹ ID %d, %dê°œ íŒŒì¼", existingGroupID, len(group))
	return nil
}

func (ds *DriveService) saveDuplicateGroups(duplicates [][]*DriveFile) error {
	log.Println("ğŸ—„ï¸ ì¤‘ë³µ ê·¸ë£¹ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì¤‘...")
	
	tx, err := ds.db.Begin()
	if err != nil {
		return fmt.Errorf("íŠ¸ëœì­ì…˜ ì‹œì‘ ì˜¤ë¥˜: %v", err)
	}
	defer tx.Rollback()

	// ê¸°ì¡´ ì¤‘ë³µ ê·¸ë£¹ ì‚­ì œ
	_, err = tx.Exec("DELETE FROM duplicate_files")
	if err != nil {
		return err
	}
	_, err = tx.Exec("DELETE FROM duplicate_groups")
	if err != nil {
		return err
	}

	for _, group := range duplicates {
		if len(group) < 2 {
			continue
		}

		// ê·¸ë£¹ ìƒì„±
		result, err := tx.Exec(`
			INSERT INTO duplicate_groups (hash, group_size)
			VALUES (?, ?)
		`, group[0].Hash, len(group))
		if err != nil {
			return err
		}

		groupID, err := result.LastInsertId()
		if err != nil {
			return err
		}

		// ê·¸ë£¹ì— íŒŒì¼ë“¤ ì¶”ê°€
		for _, file := range group {
			_, err = tx.Exec(`
				INSERT INTO duplicate_files (group_id, file_id)
				VALUES (?, ?)
			`, groupID, file.ID)
			if err != nil {
				return err
			}
		}
	}

	if err = tx.Commit(); err != nil {
		return fmt.Errorf("íŠ¸ëœì­ì…˜ ì»¤ë°‹ ì˜¤ë£Œ: %v", err)
	}

	log.Printf("âœ… %dê°œ ì¤‘ë³µ ê·¸ë£¹ì´ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë¨", len(duplicates))
	return nil
}

func (ds *DriveService) loadDuplicateGroupsPaginated(page, limit int) ([][]*DriveFile, int, error) {
	log.Printf("ğŸ—„ï¸ í˜ì´ì§€ë„¤ì´ì…˜ëœ ì¤‘ë³µ ê·¸ë£¹ ë¡œë“œ ì¤‘... (í˜ì´ì§€ %d, í•œê³„ %d)", page, limit)
	
	// ì´ ê·¸ë£¹ ê°œìˆ˜ ì¡°íšŒ
	var totalCount int
	err := ds.db.QueryRow("SELECT COUNT(*) FROM duplicate_groups").Scan(&totalCount)
	if err != nil {
		return nil, 0, fmt.Errorf("ê·¸ë£¹ ê°œìˆ˜ ì¡°íšŒ ì˜¤ë¥˜: %v", err)
	}
	
	// OFFSET ê³„ì‚°
	offset := (page - 1) * limit
	
	rows, err := ds.db.Query(`
		SELECT dg.id, dg.hash, dg.group_size,
			   f.id, f.name, f.size, f.web_view_link, f.mime_type, f.modified_time, f.hash, f.parents, f.path
		FROM duplicate_groups dg
		JOIN duplicate_files df ON dg.id = df.group_id
		JOIN files f ON df.file_id = f.id
		WHERE dg.id IN (
			SELECT id FROM duplicate_groups 
			ORDER BY id 
			LIMIT ? OFFSET ?
		)
		ORDER BY dg.id, f.name
	`, limit, offset)
	
	if err != nil {
		return nil, 0, fmt.Errorf("ì¤‘ë³µ ê·¸ë£¹ ì¡°íšŒ ì˜¤ë¥˜: %v", err)
	}
	defer rows.Close()

	groupMap := make(map[int64][]*DriveFile)
	fileCount := 0
	for rows.Next() {
		var groupID int64
		var groupHash string
		var groupSize int
		var parentsJSON string
		file := &DriveFile{}
		
		err := rows.Scan(&groupID, &groupHash, &groupSize,
						&file.ID, &file.Name, &file.Size, &file.WebViewLink,
						&file.MimeType, &file.ModifiedTime, &file.Hash, &parentsJSON, &file.Path)
		if err != nil {
			return nil, 0, fmt.Errorf("ì¤‘ë³µ ê·¸ë£¹ ìŠ¤ìº” ì˜¤ë¥˜: %v", err)
		}
		
		// Parents JSONì„ íŒŒì‹±
		if parentsJSON != "" {
			json.Unmarshal([]byte(parentsJSON), &file.Parents)
		}
		
		groupMap[groupID] = append(groupMap[groupID], file)
		fileCount++
	}

	var duplicates [][]*DriveFile
	for groupID, group := range groupMap {
		log.Printf("ğŸ“‹ ê·¸ë£¹ ID %d: %dê°œ íŒŒì¼", groupID, len(group))
		duplicates = append(duplicates, group)
	}

	log.Printf("âœ… í˜ì´ì§€ë„¤ì´ì…˜ëœ ì¤‘ë³µ ê·¸ë£¹ ë¡œë“œ ì™„ë£Œ: %dê°œ ê·¸ë£¹ (ì´ %dê°œ ì¤‘)", len(duplicates), totalCount)
	return duplicates, totalCount, nil
}

func (ds *DriveService) loadDuplicateGroups() ([][]*DriveFile, error) {
	log.Println("ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¤‘ë³µ ê·¸ë£¹ ë¡œë“œ ì¤‘...")
	
	// ë¨¼ì € ì¤‘ë³µ ê·¸ë£¹ ê°œìˆ˜ í™•ì¸
	var groupCount int
	err := ds.db.QueryRow("SELECT COUNT(*) FROM duplicate_groups").Scan(&groupCount)
	if err != nil {
		log.Printf("âš ï¸ ì¤‘ë³µ ê·¸ë£¹ ê°œìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: %v", err)
	} else {
		log.Printf("ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ì— %dê°œ ì¤‘ë³µ ê·¸ë£¹ ì¡´ì¬", groupCount)
	}
	
	rows, err := ds.db.Query(`
		SELECT dg.id, dg.hash, dg.group_size,
			   f.id, f.name, f.size, f.web_view_link, f.mime_type, f.modified_time, f.hash, f.parents, f.path
		FROM duplicate_groups dg
		JOIN duplicate_files df ON dg.id = df.group_id
		JOIN files f ON df.file_id = f.id
		ORDER BY dg.id, f.name
	`)
	if err != nil {
		log.Printf("âŒ ì¤‘ë³µ ê·¸ë£¹ ì¡°íšŒ ì¿¼ë¦¬ ì‹¤íŒ¨: %v", err)
		return nil, fmt.Errorf("ì¤‘ë³µ ê·¸ë£¹ ì¡°íšŒ ì˜¤ë¥˜: %v", err)
	}
	defer rows.Close()

	groupMap := make(map[int64][]*DriveFile)
	fileCount := 0
	for rows.Next() {
		var groupID int64
		var groupHash string
		var groupSize int
		var parentsJSON string
		file := &DriveFile{}
		
		err := rows.Scan(&groupID, &groupHash, &groupSize,
						&file.ID, &file.Name, &file.Size, &file.WebViewLink,
						&file.MimeType, &file.ModifiedTime, &file.Hash, &parentsJSON, &file.Path)
		if err != nil {
			log.Printf("âŒ ì¤‘ë³µ ê·¸ë£¹ ìŠ¤ìº” ì˜¤ë¥˜: %v", err)
			return nil, fmt.Errorf("ì¤‘ë³µ ê·¸ë£¹ ìŠ¤ìº” ì˜¤ë¥˜: %v", err)
		}
		
		// Parents JSONì„ íŒŒì‹±
		log.Printf("ğŸ” íŒŒì¼ %sì˜ parentsJSON: '%s'", file.Name, parentsJSON)
		if parentsJSON != "" {
			err := json.Unmarshal([]byte(parentsJSON), &file.Parents)
			if err != nil {
				log.Printf("âš ï¸ Parents JSON íŒŒì‹± ì‹¤íŒ¨: %v", err)
			} else {
				log.Printf("ğŸ“‹ íŒŒì‹±ëœ Parents: %v", file.Parents)
			}
		} else {
			log.Printf("âš ï¸ íŒŒì¼ %sì˜ parents ì •ë³´ê°€ ë¹„ì–´ìˆìŒ", file.Name)
		}
		
		groupMap[groupID] = append(groupMap[groupID], file)
		fileCount++
	}

	log.Printf("ğŸ“„ ì´ %dê°œ ì¤‘ë³µ íŒŒì¼ ë¡œë“œë¨", fileCount)

	var duplicates [][]*DriveFile
	for groupID, group := range groupMap {
		log.Printf("ğŸ“‹ ê·¸ë£¹ ID %d: %dê°œ íŒŒì¼", groupID, len(group))
		duplicates = append(duplicates, group)
	}

	log.Printf("âœ… ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ %dê°œ ì¤‘ë³µ ê·¸ë£¹ ë¡œë“œ ì™„ë£Œ", len(duplicates))
	return duplicates, nil
}

func (ds *DriveService) deleteFileFromDB(fileID string) error {
	tx, err := ds.db.Begin()
	if err != nil {
		return fmt.Errorf("íŠ¸ëœì­ì…˜ ì‹œì‘ ì˜¤ë¥˜: %v", err)
	}
	defer tx.Rollback()

	// duplicate_filesì—ì„œ ì‚­ì œ
	_, err = tx.Exec("DELETE FROM duplicate_files WHERE file_id = ?", fileID)
	if err != nil {
		return fmt.Errorf("duplicate_files ì‚­ì œ ì˜¤ë¥˜: %v", err)
	}

	// filesì—ì„œ ì‚­ì œ
	_, err = tx.Exec("DELETE FROM files WHERE id = ?", fileID)
	if err != nil {
		return fmt.Errorf("files ì‚­ì œ ì˜¤ë¥˜: %v", err)
	}

	if err = tx.Commit(); err != nil {
		return fmt.Errorf("íŠ¸ëœì­ì…˜ ì»¤ë°‹ ì˜¤ë¥˜: %v", err)
	}

	return nil
}

func (ds *DriveService) cleanupEmptyGroups() error {
	// íŒŒì¼ì´ 1ê°œ ì´í•˜ì¸ ê·¸ë£¹ë“¤ì„ ì°¾ì•„ì„œ ì‚­ì œ
	rows, err := ds.db.Query(`
		SELECT dg.id, COUNT(df.file_id) as file_count
		FROM duplicate_groups dg
		LEFT JOIN duplicate_files df ON dg.id = df.group_id
		GROUP BY dg.id
		HAVING file_count <= 1
	`)
	if err != nil {
		return fmt.Errorf("ë¹ˆ ê·¸ë£¹ ì¡°íšŒ ì˜¤ë¥˜: %v", err)
	}
	defer rows.Close()

	var emptyGroupIDs []int64
	for rows.Next() {
		var groupID int64
		var fileCount int
		if err := rows.Scan(&groupID, &fileCount); err != nil {
			return fmt.Errorf("ë¹ˆ ê·¸ë£¹ ìŠ¤ìº” ì˜¤ë¥˜: %v", err)
		}
		emptyGroupIDs = append(emptyGroupIDs, groupID)
	}

	// ë¹ˆ ê·¸ë£¹ë“¤ ì‚­ì œ
	for _, groupID := range emptyGroupIDs {
		_, err = ds.db.Exec("DELETE FROM duplicate_files WHERE group_id = ?", groupID)
		if err != nil {
			log.Printf("âš ï¸ duplicate_files ì‚­ì œ ì‹¤íŒ¨ (group_id: %d): %v", groupID, err)
		}
		_, err = ds.db.Exec("DELETE FROM duplicate_groups WHERE id = ?", groupID)
		if err != nil {
			log.Printf("âš ï¸ duplicate_groups ì‚­ì œ ì‹¤íŒ¨ (id: %d): %v", groupID, err)
		}
	}

	if len(emptyGroupIDs) > 0 {
		log.Printf("ğŸ—‘ï¸ %dê°œì˜ ë¹ˆ ì¤‘ë³µ ê·¸ë£¹ ì •ë¦¬ ì™„ë£Œ", len(emptyGroupIDs))
	}

	return nil
}

func (ds *DriveService) getMaxWorkers() int {
	var value string
	err := ds.db.QueryRow("SELECT value FROM settings WHERE key = 'max_workers'").Scan(&value)
	if err != nil {
		log.Printf("âš ï¸ max_workers ì„¤ì • ì¡°íšŒ ì‹¤íŒ¨, ê¸°ë³¸ê°’ 3 ì‚¬ìš©: %v", err)
		return 3
	}
	
	maxWorkers := 3
	if _, err := fmt.Sscanf(value, "%d", &maxWorkers); err != nil {
		log.Printf("âš ï¸ max_workers íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ê°’ 3 ì‚¬ìš©: %v", err)
		return 3
	}
	
	// ìµœì†Œ 1ê°œ, ìµœëŒ€ 20ê°œë¡œ ì œí•œ
	if maxWorkers < 1 {
		maxWorkers = 1
	} else if maxWorkers > 20 {
		maxWorkers = 20
	}
	
	return maxWorkers
}

func (ds *DriveService) setMaxWorkers(workers int) error {
	if workers < 1 {
		workers = 1
	} else if workers > 20 {
		workers = 20
	}
	
	_, err := ds.db.Exec(`
		INSERT OR REPLACE INTO settings (key, value, updated_at) 
		VALUES ('max_workers', ?, CURRENT_TIMESTAMP)
	`, fmt.Sprintf("%d", workers))
	
	if err != nil {
		return fmt.Errorf("max_workers ì„¤ì • ì €ì¥ ì‹¤íŒ¨: %v", err)
	}
	
	log.Printf("âš™ï¸ ë³‘ë ¬ ì‘ì—… ê°œìˆ˜ê°€ %dê°œë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤", workers)
	return nil
}

func (ds *DriveService) getAllSettings() map[string]string {
	settings := make(map[string]string)
	
	rows, err := ds.db.Query("SELECT key, value FROM settings")
	if err != nil {
		log.Printf("âš ï¸ ì„¤ì • ì¡°íšŒ ì‹¤íŒ¨: %v", err)
		return settings
	}
	defer rows.Close()
	
	for rows.Next() {
		var key, value string
		if err := rows.Scan(&key, &value); err != nil {
			continue
		}
		settings[key] = value
	}
	
	return settings
}

// í´ë” ë¹„êµ ë° ì¤‘ë³µ íŒŒì¼ ê²€ì¶œ ê¸°ëŠ¥
type FolderComparisonResult struct {
	SourceFolder      string      `json:"sourceFolder"`
	TargetFolder      string      `json:"targetFolder"`
	SourceFiles       []*DriveFile `json:"sourceFiles"`
	TargetFiles       []*DriveFile `json:"targetFiles"`
	DuplicatesInTarget []*DriveFile `json:"duplicatesInTarget"`
	TotalDuplicates   int         `json:"totalDuplicates"`
	
	// í´ë” ì‚­ì œ ê¶Œì¥ ì •ë³´
	CanDeleteTargetFolder  bool    `json:"canDeleteTargetFolder"`  // ëŒ€ìƒ í´ë” ì „ì²´ ì‚­ì œ ê°€ëŠ¥ ì—¬ë¶€
	TargetFolderName      string  `json:"targetFolderName"`       // ëŒ€ìƒ í´ë” ì´ë¦„
	TargetFolderID        string  `json:"targetFolderID"`         // ëŒ€ìƒ í´ë” ID
	DuplicationPercentage float64 `json:"duplicationPercentage"`  // ì¤‘ë³µ ë¹„ìœ¨
}

// í´ë” ë¹„êµ ì§„í–‰ ìƒí™© ì¶”ì 
type FolderComparisonProgress struct {
	Status              string `json:"status"` // "running", "completed", "error"
	CurrentStep         string `json:"currentStep"`
	SourceFolderScanned int    `json:"sourceFolderScanned"`
	SourceFolderTotal   int    `json:"sourceFolderTotal"`
	TargetFolderScanned int    `json:"targetFolderScanned"`
	TargetFolderTotal   int    `json:"targetFolderTotal"`
	HashesCalculated    int    `json:"hashesCalculated"`
	TotalHashesToCalc   int    `json:"totalHashesToCalc"`
	DuplicatesFound     int    `json:"duplicatesFound"`
	ErrorMessage        string `json:"errorMessage,omitempty"`
	StartTime           time.Time `json:"startTime"`
	LastUpdated         time.Time `json:"lastUpdated"`
}

// í´ë” ë¹„êµ ì‘ì—… êµ¬ì¡°ì²´
type FolderComparisonTask struct {
	ID                  int    `json:"id"`
	SourceFolderID      string `json:"sourceFolderId"`
	TargetFolderID      string `json:"targetFolderId"`
	Status              string `json:"status"`
	CurrentStep         string `json:"currentStep"`
	SourceFolderScanned int    `json:"sourceFolderScanned"`
	SourceFolderTotal   int    `json:"sourceFolderTotal"`
	TargetFolderScanned int    `json:"targetFolderScanned"`
	TargetFolderTotal   int    `json:"targetFolderTotal"`
	HashesCalculated    int    `json:"hashesCalculated"`
	TotalHashesToCalc   int    `json:"totalHashesToCalc"`
	DuplicatesFound     int    `json:"duplicatesFound"`
	ErrorMessage        string `json:"errorMessage"`
	CreatedAt           string `json:"createdAt"`
	UpdatedAt           string `json:"updatedAt"`
}

// ì „ì—­ í´ë” ë¹„êµ ì§„í–‰ ìƒí™© (ë©”ëª¨ë¦¬ì— ì €ì¥)
var (
	currentComparisonProgress *FolderComparisonProgress
	comparisonProgressMutex   sync.RWMutex
	lastComparisonResult      *FolderComparisonResult
	comparisonResultMutex     sync.RWMutex
	currentComparisonTask     *FolderComparisonTask
	currentTaskMutex          sync.RWMutex
)

// í´ë” ë¹„êµ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ í•¨ìˆ˜ë“¤
func updateComparisonProgress(update func(*FolderComparisonProgress)) {
	comparisonProgressMutex.Lock()
	defer comparisonProgressMutex.Unlock()
	
	if currentComparisonProgress != nil {
		update(currentComparisonProgress)
		currentComparisonProgress.LastUpdated = time.Now()
	}
}

func initComparisonProgress(sourceFolderID, targetFolderID string) {
	comparisonProgressMutex.Lock()
	defer comparisonProgressMutex.Unlock()
	
	currentComparisonProgress = &FolderComparisonProgress{
		Status:      "running",
		CurrentStep: "ì´ˆê¸°í™” ì¤‘...",
		StartTime:   time.Now(),
		LastUpdated: time.Now(),
	}
}

func getComparisonProgress() *FolderComparisonProgress {
	comparisonProgressMutex.RLock()
	defer comparisonProgressMutex.RUnlock()
	
	if currentComparisonProgress == nil {
		return nil
	}
	
	// ë³µì‚¬ë³¸ ë°˜í™˜ (ë™ì‹œì„± ì•ˆì „)
	progress := *currentComparisonProgress
	return &progress
}

func saveComparisonResult(result *FolderComparisonResult) {
	comparisonResultMutex.Lock()
	defer comparisonResultMutex.Unlock()
	
	lastComparisonResult = result
}

func getComparisonResult() *FolderComparisonResult {
	comparisonResultMutex.RLock()
	defer comparisonResultMutex.RUnlock()
	
	return lastComparisonResult
}

// í´ë” ë¹„êµ ì‘ì—…ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
func (ds *DriveService) saveComparisonTask(task *FolderComparisonTask) error {
	if task.ID == 0 {
		// ìƒˆë¡œìš´ ì‘ì—… ìƒì„±
		result, err := ds.db.Exec(`
			INSERT INTO folder_comparison_tasks 
			(source_folder_id, target_folder_id, status, current_step, 
			 source_folder_scanned, source_folder_total, target_folder_scanned, target_folder_total,
			 hashes_calculated, total_hashes_to_calc, duplicates_found, error_message, updated_at)
			VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
		`, task.SourceFolderID, task.TargetFolderID, task.Status, task.CurrentStep,
			task.SourceFolderScanned, task.SourceFolderTotal, task.TargetFolderScanned, task.TargetFolderTotal,
			task.HashesCalculated, task.TotalHashesToCalc, task.DuplicatesFound, task.ErrorMessage)
		
		if err != nil {
			return fmt.Errorf("ì‘ì—… ì €ì¥ ì‹¤íŒ¨: %v", err)
		}
		
		taskID, err := result.LastInsertId()
		if err != nil {
			return fmt.Errorf("ì‘ì—… ID ì¡°íšŒ ì‹¤íŒ¨: %v", err)
		}
		task.ID = int(taskID)
		
		log.Printf("ğŸ“ ìƒˆë¡œìš´ í´ë” ë¹„êµ ì‘ì—… ì €ì¥ë¨: ID=%d", task.ID)
	} else {
		// ê¸°ì¡´ ì‘ì—… ì—…ë°ì´íŠ¸
		_, err := ds.db.Exec(`
			UPDATE folder_comparison_tasks SET
			status = ?, current_step = ?, 
			source_folder_scanned = ?, source_folder_total = ?, 
			target_folder_scanned = ?, target_folder_total = ?,
			hashes_calculated = ?, total_hashes_to_calc = ?, 
			duplicates_found = ?, error_message = ?,
			updated_at = CURRENT_TIMESTAMP
			WHERE id = ?
		`, task.Status, task.CurrentStep,
			task.SourceFolderScanned, task.SourceFolderTotal,
			task.TargetFolderScanned, task.TargetFolderTotal,
			task.HashesCalculated, task.TotalHashesToCalc,
			task.DuplicatesFound, task.ErrorMessage, task.ID)
		
		if err != nil {
			return fmt.Errorf("ì‘ì—… ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: %v", err)
		}
	}
	
	return nil
}

// ë¯¸ì™„ë£Œëœ í´ë” ë¹„êµ ì‘ì—… ì¡°íšŒ
func (ds *DriveService) getIncompleteComparisonTask() (*FolderComparisonTask, error) {
	var task FolderComparisonTask
	
	err := ds.db.QueryRow(`
		SELECT id, source_folder_id, target_folder_id, status, current_step,
		       source_folder_scanned, source_folder_total, target_folder_scanned, target_folder_total,
		       hashes_calculated, total_hashes_to_calc, duplicates_found, error_message,
		       created_at, updated_at
		FROM folder_comparison_tasks 
		WHERE status IN ('pending', 'running') 
		ORDER BY updated_at DESC 
		LIMIT 1
	`).Scan(
		&task.ID, &task.SourceFolderID, &task.TargetFolderID, &task.Status, &task.CurrentStep,
		&task.SourceFolderScanned, &task.SourceFolderTotal, &task.TargetFolderScanned, &task.TargetFolderTotal,
		&task.HashesCalculated, &task.TotalHashesToCalc, &task.DuplicatesFound, &task.ErrorMessage,
		&task.CreatedAt, &task.UpdatedAt,
	)
	
	if err == sql.ErrNoRows {
		return nil, nil // ë¯¸ì™„ë£Œëœ ì‘ì—… ì—†ìŒ
	} else if err != nil {
		return nil, fmt.Errorf("ì‘ì—… ì¡°íšŒ ì‹¤íŒ¨: %v", err)
	}
	
	return &task, nil
}

// ì‘ì—…ì— íŒŒì¼ ì •ë³´ ì €ì¥
func (ds *DriveService) saveComparisonFiles(taskID int, files []*DriveFile, folderType string, isDuplicates []bool) error {
	tx, err := ds.db.Begin()
	if err != nil {
		return fmt.Errorf("íŠ¸ëœì­ì…˜ ì‹œì‘ ì‹¤íŒ¨: %v", err)
	}
	defer tx.Rollback()
	
	// ê¸°ì¡´ íŒŒì¼ ì •ë³´ ì‚­ì œ (í•´ë‹¹ í´ë” íƒ€ì…ë§Œ)
	_, err = tx.Exec("DELETE FROM comparison_result_files WHERE task_id = ? AND folder_type = ?", taskID, folderType)
	if err != nil {
		return fmt.Errorf("ê¸°ì¡´ íŒŒì¼ ì •ë³´ ì‚­ì œ ì‹¤íŒ¨: %v", err)
	}
	
	// ìƒˆ íŒŒì¼ ì •ë³´ ì €ì¥
	stmt, err := tx.Prepare(`
		INSERT INTO comparison_result_files 
		(task_id, file_id, file_name, file_size, file_hash, file_path, web_view_link, mime_type, modified_time, is_duplicate, folder_type)
		VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
	`)
	if err != nil {
		return fmt.Errorf("prepared statement ìƒì„± ì‹¤íŒ¨: %v", err)
	}
	defer stmt.Close()
	
	for i, file := range files {
		isDup := false
		if i < len(isDuplicates) {
			isDup = isDuplicates[i]
		}
		
		_, err = stmt.Exec(taskID, file.ID, file.Name, file.Size, file.Hash, file.Path, 
			file.WebViewLink, file.MimeType, file.ModifiedTime, isDup, folderType)
		if err != nil {
			return fmt.Errorf("íŒŒì¼ ì •ë³´ ì €ì¥ ì‹¤íŒ¨: %v", err)
		}
	}
	
	if err = tx.Commit(); err != nil {
		return fmt.Errorf("íŠ¸ëœì­ì…˜ ì»¤ë°‹ ì‹¤íŒ¨: %v", err)
	}
	
	log.Printf("ğŸ’¾ íŒŒì¼ ì •ë³´ ì €ì¥ ì™„ë£Œ: %dê°œ íŒŒì¼ (%s)", len(files), folderType)
	return nil
}

// ì €ì¥ëœ íŒŒì¼ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
func (ds *DriveService) loadComparisonFiles(taskID int, folderType string) ([]*DriveFile, error) {
	rows, err := ds.db.Query(`
		SELECT file_id, file_name, file_size, file_hash, file_path, web_view_link, mime_type, modified_time, is_duplicate
		FROM comparison_result_files 
		WHERE task_id = ? AND folder_type = ?
		ORDER BY file_name
	`, taskID, folderType)
	if err != nil {
		return nil, fmt.Errorf("íŒŒì¼ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: %v", err)
	}
	defer rows.Close()
	
	var files []*DriveFile
	for rows.Next() {
		var file DriveFile
		var isDuplicate bool
		
		err := rows.Scan(&file.ID, &file.Name, &file.Size, &file.Hash, &file.Path,
			&file.WebViewLink, &file.MimeType, &file.ModifiedTime, &isDuplicate)
		if err != nil {
			return nil, fmt.Errorf("íŒŒì¼ ì •ë³´ ìŠ¤ìº” ì‹¤íŒ¨: %v", err)
		}
		
		files = append(files, &file)
	}
	
	return files, nil
}

// ë‘ í´ë”ë¥¼ ë¹„êµí•˜ì—¬ ëŒ€ìƒ í´ë”ì˜ ì¤‘ë³µ íŒŒì¼ì„ ì°¾ëŠ”ë‹¤
func (ds *DriveService) compareFolders(sourceFolderID, targetFolderID string) (*FolderComparisonResult, error) {
	log.Printf("ğŸ” í´ë” ë¹„êµ ì‹œì‘: ê¸°ì¤€ í´ë” %s vs ëŒ€ìƒ í´ë” %s", sourceFolderID, targetFolderID)
	
	// ê¸°ì¡´ ë¯¸ì™„ë£Œ ì‘ì—… í™•ì¸
	existingTask, err := ds.getIncompleteComparisonTask()
	if err != nil {
		log.Printf("âš ï¸ ê¸°ì¡´ ì‘ì—… í™•ì¸ ì‹¤íŒ¨: %v", err)
	}
	
	var task *FolderComparisonTask
	var sourceFiles, targetFiles []*DriveFile
	
	if existingTask != nil && existingTask.SourceFolderID == sourceFolderID && existingTask.TargetFolderID == targetFolderID {
		// ê¸°ì¡´ ì‘ì—… ì¬ê°œ
		log.Printf("ğŸ”„ ê¸°ì¡´ ì‘ì—… ì¬ê°œ: ID=%d", existingTask.ID)
		task = existingTask
		task.Status = "running"
		task.CurrentStep = "ê¸°ì¡´ ì‘ì—… ì¬ê°œ ì¤‘..."
		ds.saveComparisonTask(task)
		
		// ì €ì¥ëœ íŒŒì¼ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
		if task.SourceFolderTotal > 0 {
			sourceFiles, err = ds.loadComparisonFiles(task.ID, "source")
			if err != nil {
				log.Printf("âš ï¸ ê¸°ì¤€ í´ë” íŒŒì¼ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: %v", err)
				sourceFiles = nil
			} else {
				log.Printf("ğŸ“‚ ì €ì¥ëœ ê¸°ì¤€ í´ë” íŒŒì¼ ì •ë³´ ë¶ˆëŸ¬ì˜´: %dê°œ", len(sourceFiles))
			}
		}
		
		if task.TargetFolderTotal > 0 {
			targetFiles, err = ds.loadComparisonFiles(task.ID, "target")
			if err != nil {
				log.Printf("âš ï¸ ëŒ€ìƒ í´ë” íŒŒì¼ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: %v", err)
				targetFiles = nil
			} else {
				log.Printf("ğŸ“‚ ì €ì¥ëœ ëŒ€ìƒ í´ë” íŒŒì¼ ì •ë³´ ë¶ˆëŸ¬ì˜´: %dê°œ", len(targetFiles))
			}
		}
	} else {
		// ìƒˆë¡œìš´ ì‘ì—… ì‹œì‘
		task = &FolderComparisonTask{
			SourceFolderID: sourceFolderID,
			TargetFolderID: targetFolderID,
			Status:         "running",
			CurrentStep:    "ì´ˆê¸°í™” ì¤‘...",
		}
		err = ds.saveComparisonTask(task)
		if err != nil {
			return nil, fmt.Errorf("ì‘ì—… ì €ì¥ ì‹¤íŒ¨: %v", err)
		}
		log.Printf("ğŸ“ ìƒˆë¡œìš´ í´ë” ë¹„êµ ì‘ì—… ìƒì„±: ID=%d", task.ID)
	}
	
	// í˜„ì¬ ì‘ì—…ì„ ì „ì—­ ë³€ìˆ˜ì— ì €ì¥
	currentTaskMutex.Lock()
	currentComparisonTask = task
	currentTaskMutex.Unlock()
	
	// ì§„í–‰ ìƒí™© ì´ˆê¸°í™”
	initComparisonProgress(sourceFolderID, targetFolderID)

	// ê¸°ì¤€ í´ë” íŒŒì¼ ìŠ¤ìº” (ì €ì¥ëœ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ)
	if sourceFiles == nil {
		updateComparisonProgress(func(p *FolderComparisonProgress) {
			p.CurrentStep = "ê¸°ì¤€ í´ë” ìŠ¤ìº” ì¤‘..."
		})
		
		sourceFiles, err = ds.getFilesInFolderWithProgress(sourceFolderID, true, "source")
		if err != nil {
			updateComparisonProgress(func(p *FolderComparisonProgress) {
				p.Status = "error"
				p.ErrorMessage = fmt.Sprintf("ê¸°ì¤€ í´ë” íŒŒì¼ ì¡°íšŒ ì‹¤íŒ¨: %v", err)
			})
			return nil, fmt.Errorf("ê¸°ì¤€ í´ë” íŒŒì¼ ì¡°íšŒ ì‹¤íŒ¨: %v", err)
		}
		log.Printf("ğŸ“ ê¸°ì¤€ í´ë”ì—ì„œ %dê°œ íŒŒì¼ ë°œê²¬", len(sourceFiles))
		
		// ìŠ¤ìº” ì™„ë£Œ í›„ íŒŒì¼ ì •ë³´ ì €ì¥
		err = ds.saveComparisonFiles(task.ID, sourceFiles, "source", nil)
		if err != nil {
			log.Printf("âš ï¸ ê¸°ì¤€ í´ë” íŒŒì¼ ì •ë³´ ì €ì¥ ì‹¤íŒ¨: %v", err)
		}
		
		// ì‘ì—… ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
		task.SourceFolderTotal = len(sourceFiles)
		task.SourceFolderScanned = len(sourceFiles)
		ds.saveComparisonTask(task)
	} else {
		log.Printf("ğŸ“‚ ì €ì¥ëœ ê¸°ì¤€ í´ë” íŒŒì¼ ì •ë³´ ì‚¬ìš©: %dê°œ", len(sourceFiles))
	}

	// ëŒ€ìƒ í´ë” íŒŒì¼ ìŠ¤ìº” (ì €ì¥ëœ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ)
	if targetFiles == nil {
		updateComparisonProgress(func(p *FolderComparisonProgress) {
			p.CurrentStep = "ëŒ€ìƒ í´ë” ìŠ¤ìº” ì¤‘..."
			p.SourceFolderTotal = len(sourceFiles)
		})
		
		targetFiles, err = ds.getFilesInFolderWithProgress(targetFolderID, true, "target")
		if err != nil {
			updateComparisonProgress(func(p *FolderComparisonProgress) {
				p.Status = "error"
				p.ErrorMessage = fmt.Sprintf("ëŒ€ìƒ í´ë” íŒŒì¼ ì¡°íšŒ ì‹¤íŒ¨: %v", err)
			})
			return nil, fmt.Errorf("ëŒ€ìƒ í´ë” íŒŒì¼ ì¡°íšŒ ì‹¤íŒ¨: %v", err)
		}
		log.Printf("ğŸ“ ëŒ€ìƒ í´ë”ì—ì„œ %dê°œ íŒŒì¼ ë°œê²¬", len(targetFiles))
		
		// ìŠ¤ìº” ì™„ë£Œ í›„ íŒŒì¼ ì •ë³´ ì €ì¥
		err = ds.saveComparisonFiles(task.ID, targetFiles, "target", nil)
		if err != nil {
			log.Printf("âš ï¸ ëŒ€ìƒ í´ë” íŒŒì¼ ì •ë³´ ì €ì¥ ì‹¤íŒ¨: %v", err)
		}
		
		// ì‘ì—… ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
		task.TargetFolderTotal = len(targetFiles)
		task.TargetFolderScanned = len(targetFiles)
		ds.saveComparisonTask(task)
	} else {
		log.Printf("ğŸ“‚ ì €ì¥ëœ ëŒ€ìƒ í´ë” íŒŒì¼ ì •ë³´ ì‚¬ìš©: %dê°œ", len(targetFiles))
		
		updateComparisonProgress(func(p *FolderComparisonProgress) {
			p.SourceFolderTotal = len(sourceFiles)
		})
	}

	// ê¸°ì¤€ í´ë” íŒŒì¼ë“¤ì˜ í•´ì‹œ ë§µ ìƒì„±
	updateComparisonProgress(func(p *FolderComparisonProgress) {
		p.CurrentStep = "í•´ì‹œ ë§µ ìƒì„± ì¤‘..."
		p.TargetFolderTotal = len(targetFiles)
	})
	
	sourceFileHashes := make(map[string]*DriveFile)
	for _, file := range sourceFiles {
		if file.Hash != "" {
			sourceFileHashes[file.Hash] = file
		}
	}
	log.Printf("ğŸ”‘ ê¸°ì¤€ í´ë”ì—ì„œ %dê°œ íŒŒì¼ì˜ í•´ì‹œ ìƒì„±", len(sourceFileHashes))

	// ëŒ€ìƒ í´ë”ì—ì„œ ì¤‘ë³µ íŒŒì¼ ì°¾ê¸°
	updateComparisonProgress(func(p *FolderComparisonProgress) {
		p.CurrentStep = "ì¤‘ë³µ íŒŒì¼ ê²€ì¶œ ì¤‘..."
	})
	
	var duplicatesInTarget []*DriveFile
	for i, targetFile := range targetFiles {
		if targetFile.Hash != "" {
			if sourceFile, exists := sourceFileHashes[targetFile.Hash]; exists {
				log.Printf("ğŸ”„ ì¤‘ë³µ ë°œê²¬: %s (ëŒ€ìƒ) = %s (ê¸°ì¤€)", targetFile.Name, sourceFile.Name)
				// ì¶”ê°€ ì •ë³´ë¥¼ í¬í•¨í•œ ì¤‘ë³µ íŒŒì¼ ì •ë³´ ì„¤ì •
				duplicateFile := &DriveFile{
					ID:           targetFile.ID,
					Name:         targetFile.Name,
					Size:         targetFile.Size,
					WebViewLink:  targetFile.WebViewLink,
					MimeType:     targetFile.MimeType,
					ModifiedTime: targetFile.ModifiedTime,
					Hash:         targetFile.Hash,
					Parents:      targetFile.Parents,
					Path:         targetFile.Path,
				}
				duplicatesInTarget = append(duplicatesInTarget, duplicateFile)
				
				// ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
				updateComparisonProgress(func(p *FolderComparisonProgress) {
					p.DuplicatesFound = len(duplicatesInTarget)
				})
			}
		}
		
		// ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ ë° ì£¼ê¸°ì  ì €ì¥ (50ê°œë§ˆë‹¤)
		if i%50 == 0 || i == len(targetFiles)-1 {
			updateComparisonProgress(func(p *FolderComparisonProgress) {
				p.CurrentStep = fmt.Sprintf("ì¤‘ë³µ íŒŒì¼ ê²€ì¶œ ì¤‘... (%d/%d)", i+1, len(targetFiles))
			})
			
			// ì‘ì—… ì§„í–‰ ìƒí™©ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
			task.DuplicatesFound = len(duplicatesInTarget)
			ds.saveComparisonTask(task)
		}
	}

	// ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸
	updateComparisonProgress(func(p *FolderComparisonProgress) {
		p.Status = "completed"
		p.CurrentStep = "ì™„ë£Œ"
		p.DuplicatesFound = len(duplicatesInTarget)
	})

	// ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…ì„ ì™„ë£Œë¡œ í‘œì‹œ
	task.Status = "completed"
	task.CurrentStep = "ì™„ë£Œ"
	task.DuplicatesFound = len(duplicatesInTarget)
	ds.saveComparisonTask(task)

	// í´ë” ì‚­ì œ ê¶Œì¥ ë¶„ì„
	canDeleteTargetFolder := false
	duplicationPercentage := 0.0
	var targetFolderName string
	
	if len(targetFiles) > 0 {
		duplicationPercentage = float64(len(duplicatesInTarget)) / float64(len(targetFiles)) * 100
		// 100% ì¤‘ë³µì´ë©´ í´ë” ì „ì²´ ì‚­ì œ ê¶Œì¥
		canDeleteTargetFolder = duplicationPercentage >= 100.0
		
		if canDeleteTargetFolder {
			log.Printf("ğŸ¯ í´ë” ì „ì²´ ì‚­ì œ ê¶Œì¥: ëŒ€ìƒ í´ë”ì˜ %.1f%% (%d/%d)ê°€ ì¤‘ë³µë¨", 
				duplicationPercentage, len(duplicatesInTarget), len(targetFiles))
		}
	}
	
	// ëŒ€ìƒ í´ë” ì •ë³´ ì¡°íšŒ
	if canDeleteTargetFolder {
		folderInfo, err := ds.service.Files.Get(targetFolderID).Fields("id,name").Do()
		if err != nil {
			log.Printf("âš ï¸ ëŒ€ìƒ í´ë” ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: %v", err)
		} else {
			targetFolderName = folderInfo.Name
		}
	}

	result := &FolderComparisonResult{
		SourceFolder:       sourceFolderID,
		TargetFolder:       targetFolderID,
		SourceFiles:        sourceFiles,
		TargetFiles:        targetFiles,
		DuplicatesInTarget: duplicatesInTarget,
		TotalDuplicates:    len(duplicatesInTarget),
		
		// í´ë” ì‚­ì œ ê¶Œì¥ ì •ë³´
		CanDeleteTargetFolder:  canDeleteTargetFolder,
		TargetFolderName:      targetFolderName,
		TargetFolderID:        targetFolderID,
		DuplicationPercentage: duplicationPercentage,
	}

	// ê²°ê³¼ ì €ì¥
	saveComparisonResult(result)
	
	log.Printf("âœ… í´ë” ë¹„êµ ì™„ë£Œ: ëŒ€ìƒ í´ë”ì—ì„œ %dê°œ ì¤‘ë³µ íŒŒì¼ ë°œê²¬", len(duplicatesInTarget))
	return result, nil
}

// ì§„í–‰ ìƒí™© ì¶”ì ê³¼ í•¨ê»˜ í´ë” ìŠ¤ìº”
func (ds *DriveService) getFilesInFolderWithProgress(folderID string, calculateHashes bool, folderType string) ([]*DriveFile, error) {
	var allFiles []*DriveFile
	pageToken := ""

	for {
		query := fmt.Sprintf("'%s' in parents and trashed=false", folderID)
		listCall := ds.service.Files.List().
			Q(query).
			Fields("nextPageToken, files(id, name, size, mimeType, modifiedTime, webViewLink, parents)").
			PageSize(1000)

		if pageToken != "" {
			listCall = listCall.PageToken(pageToken)
		}

		response, err := listCall.Do()
		if err != nil {
			return nil, fmt.Errorf("í´ë” íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: %v", err)
		}

		for i, file := range response.Files {
			// í´ë”ëŠ” ì œì™¸, íŒŒì¼ë§Œ ì²˜ë¦¬
			if file.MimeType != "application/vnd.google-apps.folder" {
				// ë¹ˆ íŒŒì¼ë§Œ í•„í„°ë§
				if file.Size <= 0 {
					log.Printf("â­ï¸ ë¹ˆ íŒŒì¼ ìŠ¤í‚µ: %s", file.Name)
					continue
				}
				
				driveFile := &DriveFile{
					ID:           file.Id,
					Name:         file.Name,
					Size:         file.Size,
					WebViewLink:  file.WebViewLink,
					MimeType:     file.MimeType,
					ModifiedTime: file.ModifiedTime,
					Parents:      file.Parents,
				}

				// ê²½ë¡œ ê³„ì‚°
				if len(file.Parents) > 0 {
					driveFile.Path = ds.buildFullPath(file.Parents[0])
				} else {
					driveFile.Path = "/"
				}

				// í•´ì‹œëŠ” ë‚˜ì¤‘ì— ë³‘ë ¬ë¡œ ê³„ì‚°

				allFiles = append(allFiles, driveFile)
				
				// ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
				if folderType == "source" {
					updateComparisonProgress(func(p *FolderComparisonProgress) {
						p.SourceFolderScanned = len(allFiles)
					})
				} else {
					updateComparisonProgress(func(p *FolderComparisonProgress) {
						p.TargetFolderScanned = len(allFiles)
					})
				}
			} else {
				// í•˜ìœ„ í´ë”ê°€ ìˆëŠ” ê²½ìš° ì¬ê·€ì ìœ¼ë¡œ ì²˜ë¦¬
				subFiles, err := ds.getFilesInFolderWithProgress(file.Id, calculateHashes, folderType)
				if err != nil {
					log.Printf("âš ï¸ í•˜ìœ„ í´ë” ì²˜ë¦¬ ì‹¤íŒ¨ (%s): %v", file.Name, err)
					continue
				}
				allFiles = append(allFiles, subFiles...)
			}
			
			// 100ê°œë§ˆë‹¤ ì§„í–‰ ìƒí™© ë¡œê·¸
			if (i+1)%100 == 0 {
				log.Printf("ğŸ“„ %s í´ë” ìŠ¤ìº” ì¤‘: %dê°œ íŒŒì¼ ì²˜ë¦¬ë¨", folderType, len(allFiles))
			}
		}

		pageToken = response.NextPageToken
		if pageToken == "" {
			break
		}
	}

	// íŒŒì¼ ìŠ¤ìº” ì™„ë£Œ ì•Œë¦¼
	log.Printf("âœ… í´ë” ìŠ¤ìº” ì™„ë£Œ: %s íƒ€ì…, %dê°œ íŒŒì¼ ë°œê²¬", folderType, len(allFiles))
	
	// í•´ì‹œ ê³„ì‚°ì´ í•„ìš”í•œ ê²½ìš° ì¶©ë¶„í•œ ê²€ì¦ í›„ ë³‘ë ¬ ì²˜ë¦¬
	if calculateHashes {
		log.Printf("ğŸ” í•´ì‹œ ê³„ì‚° ì¤€ë¹„ ì¤‘: %s í´ë”", folderType)
		
		// íŒŒì¼ ìŠ¤ìº”ì´ ì™„ì „íˆ ëë‚  ë•Œê¹Œì§€ ì ì‹œ ëŒ€ê¸°
		time.Sleep(500 * time.Millisecond)
		
		// í¬ê¸°ê°€ 0ë³´ë‹¤ í° íŒŒì¼ë“¤ë§Œ í•„í„°ë§í•˜ê³  ìœ íš¨ì„± ê²€ì¦
		var filesToHash []*DriveFile
		for _, file := range allFiles {
			if file.Size > 0 && file.ID != "" && file.Name != "" {
				// íŒŒì¼ ì •ë³´ê°€ ì™„ì „í•œì§€ í•œ ë²ˆ ë” ê²€ì¦
				if len(file.ID) > 10 { // Google Drive íŒŒì¼ IDëŠ” ì¼ë°˜ì ìœ¼ë¡œ 28ì ì´ìƒ
					filesToHash = append(filesToHash, file)
				} else {
					log.Printf("âš ï¸ ë¶ˆì™„ì „í•œ íŒŒì¼ ì •ë³´ ê±´ë„ˆëœ€: ID=%s, Name=%s", file.ID, file.Name)
				}
			}
		}
		
		log.Printf("ğŸ“Š í•´ì‹œ ê³„ì‚° ëŒ€ìƒ: ì „ì²´ %dê°œ ì¤‘ %dê°œ íŒŒì¼ (í¬ê¸° > 0, ìœ íš¨í•œ ID)", len(allFiles), len(filesToHash))
		
		if len(filesToHash) > 0 {
			// ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ë¥¼ ë” ëª…í™•í•˜ê²Œ
			updateComparisonProgress(func(p *FolderComparisonProgress) {
				if folderType == "source" {
					p.CurrentStep = fmt.Sprintf("ğŸ“ ê¸°ì¤€ í´ë” ìŠ¤ìº” ì™„ë£Œ (%dê°œ) â†’ ğŸ”‘ í•´ì‹œ ê³„ì‚° ì‹œì‘...", len(allFiles))
				} else {
					p.CurrentStep = fmt.Sprintf("ğŸ“ ëŒ€ìƒ í´ë” ìŠ¤ìº” ì™„ë£Œ (%dê°œ) â†’ ğŸ”‘ í•´ì‹œ ê³„ì‚° ì‹œì‘...", len(allFiles))
				}
				p.TotalHashesToCalc = len(filesToHash)
			})
			
			// í•´ì‹œ ê³„ì‚° ì‹œì‘ ì „ í•œ ë²ˆ ë” ëŒ€ê¸°
			time.Sleep(1 * time.Second)
			log.Printf("ğŸš€ í•´ì‹œ ê³„ì‚° ì‹œì‘: %dê°œ íŒŒì¼", len(filesToHash))
			
			// ë³‘ë ¬ í•´ì‹œ ê³„ì‚° (ì„¤ì •ëœ ì›Œì»¤ ê°œìˆ˜ ì‚¬ìš©)
			maxWorkers := getMaxWorkers()
			err := ds.calculateHashesInParallel(filesToHash, maxWorkers)
			if err != nil {
				log.Printf("âš ï¸ ë³‘ë ¬ í•´ì‹œ ê³„ì‚° ì‹¤íŒ¨: %v", err)
			} else {
				log.Printf("âœ… í•´ì‹œ ê³„ì‚° ì™„ë£Œ: %s í´ë”", folderType)
			}
		} else {
			log.Printf("â„¹ï¸ í•´ì‹œ ê³„ì‚°í•  íŒŒì¼ì´ ì—†ìŒ: %s í´ë”", folderType)
		}
	}

	return allFiles, nil
}

// í´ë” ë‚´ì˜ ëª¨ë“  íŒŒì¼ì„ ì¬ê·€ì ìœ¼ë¡œ ì¡°íšŒí•˜ê³  í•´ì‹œë¥¼ ê³„ì‚°í•œë‹¤ (ê¸°ì¡´ í•¨ìˆ˜ ìœ ì§€)
func (ds *DriveService) getFilesInFolder(folderID string, calculateHashes bool) ([]*DriveFile, error) {
	var allFiles []*DriveFile
	pageToken := ""

	for {
		query := fmt.Sprintf("'%s' in parents and trashed=false", folderID)
		listCall := ds.service.Files.List().
			Q(query).
			Fields("nextPageToken, files(id, name, size, mimeType, modifiedTime, webViewLink, parents)").
			PageSize(1000)

		if pageToken != "" {
			listCall = listCall.PageToken(pageToken)
		}

		response, err := listCall.Do()
		if err != nil {
			return nil, fmt.Errorf("í´ë” íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: %v", err)
		}

		for _, file := range response.Files {
			// í´ë”ëŠ” ì œì™¸, íŒŒì¼ë§Œ ì²˜ë¦¬
			if file.MimeType != "application/vnd.google-apps.folder" {
				driveFile := &DriveFile{
					ID:           file.Id,
					Name:         file.Name,
					Size:         file.Size,
					WebViewLink:  file.WebViewLink,
					MimeType:     file.MimeType,
					ModifiedTime: file.ModifiedTime,
					Parents:      file.Parents,
				}

				// ê²½ë¡œ ê³„ì‚°
				if len(file.Parents) > 0 {
					driveFile.Path = ds.buildFullPath(file.Parents[0])
				} else {
					driveFile.Path = "/"
				}

				// í•´ì‹œ ê³„ì‚°ì´ í•„ìš”í•œ ê²½ìš°
				if calculateHashes && file.Size > 0 {
					hash, err := ds.calculateFileHash(file.Id)
					if err != nil {
						log.Printf("âš ï¸ í•´ì‹œ ê³„ì‚° ì‹¤íŒ¨ (%s): %v", file.Name, err)
						continue
					}
					driveFile.Hash = hash
				}

				allFiles = append(allFiles, driveFile)
			} else {
				// í•˜ìœ„ í´ë”ê°€ ìˆëŠ” ê²½ìš° ì¬ê·€ì ìœ¼ë¡œ ì²˜ë¦¬
				subFiles, err := ds.getFilesInFolder(file.Id, calculateHashes)
				if err != nil {
					log.Printf("âš ï¸ í•˜ìœ„ í´ë” ì²˜ë¦¬ ì‹¤íŒ¨ (%s): %v", file.Name, err)
					continue
				}
				allFiles = append(allFiles, subFiles...)
			}
		}

		pageToken = response.NextPageToken
		if pageToken == "" {
			break
		}
	}

	return allFiles, nil
}

// í´ë” IDë¥¼ URLì—ì„œ ì¶”ì¶œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜
func extractFolderIDFromURL(folderURL string) string {
	// https://drive.google.com/drive/folders/1ABC123 í˜•íƒœì—ì„œ ID ì¶”ì¶œ
	re := regexp.MustCompile(`folders/([a-zA-Z0-9-_]+)`)
	matches := re.FindStringSubmatch(folderURL)
	if len(matches) > 1 {
		return matches[1]
	}
	return folderURL // URLì´ ì•„ë‹Œ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜ (ì´ë¯¸ IDì¼ ìˆ˜ ìˆìŒ)
}

func (ds *DriveService) clearAllData() error {
	log.Println("ğŸ—‘ï¸ ëª¨ë“  ë°ì´í„° ì‚­ì œ ì¤‘...")
	
	_, err := ds.db.Exec("DELETE FROM duplicate_files")
	if err != nil {
		return err
	}
	_, err = ds.db.Exec("DELETE FROM duplicate_groups")
	if err != nil {
		return err
	}
	_, err = ds.db.Exec("DELETE FROM files")
	if err != nil {
		return err
	}
	_, err = ds.db.Exec("DELETE FROM progress")
	if err != nil {
		return err
	}
	
	log.Println("âœ… ëª¨ë“  ë°ì´í„° ì‚­ì œ ì™„ë£Œ")
	return nil
}

func (ds *DriveService) ListAllFiles() ([]*DriveFile, error) {
	// DBì—ì„œ íŒŒì¼ ëª©ë¡ ë¡œë“œ ì‹œë„
	dbFiles, err := ds.loadFilesFromDB()
	if err == nil && len(dbFiles) > 0 {
		log.Printf("âœ… ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ %dê°œ íŒŒì¼ ë¡œë“œ ì™„ë£Œ", len(dbFiles))
		return dbFiles, nil
	}
	log.Println("â„¹ï¸ ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¹„ì–´ìˆê±°ë‚˜ ì˜¤ë¥˜ ë°œìƒ. ìƒˆë¡œ ì¡°íšŒí•©ë‹ˆë‹¤.")

	// ì§„í–‰ ìƒíƒœ í™•ì¸ (ì¬ê°œ ê°€ëŠ¥í•œì§€)
	progress, err := ds.loadProgress()
	if err == nil && progress.Status == "scanning" && progress.LastPageToken != "" {
		log.Printf("ğŸ”„ ì´ì „ ìŠ¤ìº”ì„ %d í˜ì´ì§€ë¶€í„° ì¬ê°œí•©ë‹ˆë‹¤", progress.LastPageCount+1)
		return ds.resumeFileScanning(progress)
	}

	// ìƒˆë¡œìš´ ìŠ¤ìº” ì‹œì‘
	return ds.startNewFileScanning()
}

func (ds *DriveService) startNewFileScanning() ([]*DriveFile, error) {
	var allFiles []*DriveFile
	pageToken := ""
	pageCount := 0

	log.Println("ğŸ“„ Google Drive íŒŒì¼ ëª©ë¡ì„ í˜ì´ì§€ë³„ë¡œ ì¡°íšŒí•˜ê³  ìˆìŠµë‹ˆë‹¤...")

	// ì§„í–‰ ìƒíƒœ ì´ˆê¸°í™”
	progress := ProgressData{
		Status:        "scanning",
		LastPageCount: 0,
		LastPageToken: "",
	}
	ds.saveProgress(progress)

	for {
		pageCount++
		log.Printf("ğŸ“‘ í˜ì´ì§€ %d ì¡°íšŒ ì¤‘...", pageCount)
		
		query := ds.service.Files.List().
			Q("trashed=false").
			PageSize(1000).
			Fields("nextPageToken, files(id, name, size, webViewLink, mimeType, modifiedTime, parents)")

		if pageToken != "" {
			query = query.PageToken(pageToken)
		}

		var result *drive.FileList
		err := ds.retryWithBackoff(func() error {
			var err error
			result, err = query.Do()
			return err
		})
		
		if err != nil {
			log.Printf("âŒ í˜ì´ì§€ %d ì¡°íšŒ ì‹¤íŒ¨: %v", pageCount, err)
			
			// ì§„í–‰ ìƒíƒœ ì €ì¥ (ì¬ê°œ ê°€ëŠ¥í•˜ë„ë¡)
			progress.LastPageCount = pageCount - 1
			progress.LastPageToken = pageToken
			progress.Status = "interrupted"
			ds.saveProgress(progress)
			
			// 5í˜ì´ì§€ ì´ìƒ ì„±ê³µì ìœ¼ë¡œ ì¡°íšŒí–ˆë‹¤ë©´ ë¶€ë¶„ ê²°ê³¼ë¼ë„ ë°˜í™˜
			if pageCount > 5 && len(allFiles) > 0 {
				log.Printf("âš ï¸ %dê°œ í˜ì´ì§€ê¹Œì§€ ì„±ê³µí•œ ë¶€ë¶„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤ (ì´ %dê°œ íŒŒì¼)", pageCount-1, len(allFiles))
				
				// ë¶€ë¶„ ê²°ê³¼ë¥¼ DBì— ì €ì¥
				if err := ds.saveFilesToDB(allFiles); err != nil {
					log.Printf("âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: %v", err)
				}
				
				return allFiles, nil
			}
			
			return nil, fmt.Errorf("íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: %v", err)
		}

		validFiles := 0
		for _, file := range result.Files {
			if file.Size > 0 {
				log.Printf("ğŸ” APIì—ì„œ ë°›ì€ íŒŒì¼: %s, Parents: %v", file.Name, file.Parents)
				driveFile := &DriveFile{
					ID:           file.Id,
					Name:         file.Name,
					Size:         file.Size,
					WebViewLink:  file.WebViewLink,
					MimeType:     file.MimeType,
					ModifiedTime: file.ModifiedTime,
					Parents:      file.Parents,
					Path:         "", // ë‚˜ì¤‘ì— í•„ìš”í•  ë•Œ ê³„ì‚°
				}
				
				allFiles = append(allFiles, driveFile)
				validFiles++
			}
		}
		
		log.Printf("âœ… í˜ì´ì§€ %d: %dê°œ íŒŒì¼ ë°œê²¬ (í¬ê¸°ê°€ ìˆëŠ” íŒŒì¼ %dê°œ)", pageCount, len(result.Files), validFiles)

		// ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
		progress.LastPageCount = pageCount
		progress.LastPageToken = result.NextPageToken
		ds.saveProgress(progress)

		// 20í˜ì´ì§€ë§ˆë‹¤ ì¤‘ê°„ ì €ì¥ (20,000ê°œ íŒŒì¼ë§ˆë‹¤)
		if pageCount%20 == 0 {
			log.Printf("ğŸ”„ ì¤‘ê°„ ì €ì¥: %dê°œ í˜ì´ì§€ê¹Œì§€ %dê°œ íŒŒì¼", pageCount, len(allFiles))
			if err := ds.saveFilesToDB(allFiles); err != nil {
				log.Printf("âš ï¸ ì¤‘ê°„ ì €ì¥ ì‹¤íŒ¨: %v", err)
			}
		}

		pageToken = result.NextPageToken
		if pageToken == "" {
			break
		}
	}

	log.Printf("ğŸ“‹ ì „ì²´ ì¡°íšŒ ì™„ë£Œ: %dê°œ í˜ì´ì§€ì—ì„œ ì´ %dê°œ íŒŒì¼", pageCount, len(allFiles))
	
	// ì™„ë£Œ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸
	progress.Status = "scan_completed"
	ds.saveProgress(progress)
	
	// íŒŒì¼ ëª©ë¡ì„ DBì— ì €ì¥
	if err := ds.saveFilesToDB(allFiles); err != nil {
		log.Printf("âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: %v", err)
	}
	
	return allFiles, nil
}

func (ds *DriveService) resumeFileScanning(progress *ProgressData) ([]*DriveFile, error) {
	// ê¸°ì¡´ íŒŒì¼ë“¤ ë¡œë“œ
	allFiles, err := ds.loadFilesFromDB()
	if err != nil {
		log.Printf("âš ï¸ ê¸°ì¡´ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨, ìƒˆë¡œ ì‹œì‘í•©ë‹ˆë‹¤: %v", err)
		return ds.startNewFileScanning()
	}

	pageToken := progress.LastPageToken
	pageCount := progress.LastPageCount

	log.Printf("ğŸ”„ í˜ì´ì§€ %dë¶€í„° íŒŒì¼ ìŠ¤ìº”ì„ ì¬ê°œí•©ë‹ˆë‹¤ (ê¸°ì¡´ %dê°œ íŒŒì¼)", pageCount+1, len(allFiles))

	for pageToken != "" {
		pageCount++
		log.Printf("ğŸ“‘ í˜ì´ì§€ %d ì¡°íšŒ ì¤‘... (ì¬ê°œ ëª¨ë“œ)", pageCount)
		
		query := ds.service.Files.List().
			Q("trashed=false").
			PageSize(1000).
			Fields("nextPageToken, files(id, name, size, webViewLink, mimeType, modifiedTime, parents)").
			PageToken(pageToken)

		var result *drive.FileList
		err := ds.retryWithBackoff(func() error {
			var err error
			result, err = query.Do()
			return err
		})
		
		if err != nil {
			log.Printf("âŒ í˜ì´ì§€ %d ì¡°íšŒ ì‹¤íŒ¨: %v", pageCount, err)
			
			// ì§„í–‰ ìƒíƒœ ì €ì¥
			progress.LastPageCount = pageCount - 1
			progress.LastPageToken = pageToken
			progress.Status = "interrupted"
			ds.saveProgress(*progress)
			
			return nil, fmt.Errorf("íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: %v", err)
		}

		validFiles := 0
		var newFiles []*DriveFile
		for _, file := range result.Files {
			if file.Size > 0 {
				log.Printf("ğŸ” APIì—ì„œ ë°›ì€ íŒŒì¼ (resume): %s, Parents: %v", file.Name, file.Parents)
				driveFile := &DriveFile{
					ID:           file.Id,
					Name:         file.Name,
					Size:         file.Size,
					WebViewLink:  file.WebViewLink,
					MimeType:     file.MimeType,
					ModifiedTime: file.ModifiedTime,
					Parents:      file.Parents,
					Path:         "", // ë‚˜ì¤‘ì— í•„ìš”í•  ë•Œ ê³„ì‚°
				}
				
				allFiles = append(allFiles, driveFile)
				newFiles = append(newFiles, driveFile)
				validFiles++
			}
		}
		
		log.Printf("âœ… í˜ì´ì§€ %d: %dê°œ íŒŒì¼ ë°œê²¬ (í¬ê¸°ê°€ ìˆëŠ” íŒŒì¼ %dê°œ)", pageCount, len(result.Files), validFiles)

		// ìƒˆ íŒŒì¼ë“¤ì„ DBì— ì¶”ê°€
		if len(newFiles) > 0 {
			if err := ds.saveFilesToDB(newFiles); err != nil {
				log.Printf("âš ï¸ ìƒˆ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: %v", err)
			}
		}

		// ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
		progress.LastPageCount = pageCount
		progress.LastPageToken = result.NextPageToken
		ds.saveProgress(*progress)

		pageToken = result.NextPageToken
	}

	log.Printf("ğŸ“‹ ìŠ¤ìº” ì¬ê°œ ì™„ë£Œ: %dê°œ í˜ì´ì§€ì—ì„œ ì´ %dê°œ íŒŒì¼", pageCount, len(allFiles))
	
	// ì™„ë£Œ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸
	progress.Status = "scan_completed"
	ds.saveProgress(*progress)
	
	return allFiles, nil
}

func (ds *DriveService) retryWithBackoff(operation func() error) error {
	maxRetries := 5
	baseDelay := time.Second
	maxDelay := 64 * time.Second

	for attempt := 0; attempt < maxRetries; attempt++ {
		err := operation()
		if err == nil {
			return nil
		}

		// Google API ì—ëŸ¬ ì²´í¬
		if apiErr, ok := err.(*googleapi.Error); ok {
			switch apiErr.Code {
			case 500, 502, 503, 504: // ì„œë²„ ì—ëŸ¬
				if attempt == maxRetries-1 {
					return err
				}
				delay := time.Duration(math.Pow(2, float64(attempt))) * baseDelay
				if delay > maxDelay {
					delay = maxDelay
				}
				log.Printf("âš ï¸ API ì„œë²„ ì˜¤ë¥˜ (ì‹œë„ %d/%d): %v - %v í›„ ì¬ì‹œë„", attempt+1, maxRetries, apiErr.Code, delay)
				time.Sleep(delay)
				continue
			case 429: // Rate limit exceeded
				if attempt == maxRetries-1 {
					return err
				}
				delay := time.Duration(math.Pow(2, float64(attempt))) * baseDelay
				if delay > maxDelay {
					delay = maxDelay
				}
				log.Printf("âš ï¸ API ì†ë„ ì œí•œ (ì‹œë„ %d/%d): %v í›„ ì¬ì‹œë„", attempt+1, maxRetries, delay)
				time.Sleep(delay)
				continue
			default:
				return err
			}
		}

		// ê¸°íƒ€ ì¼ì‹œì  ì˜¤ë¥˜ ì²´í¬
		errStr := strings.ToLower(err.Error())
		if strings.Contains(errStr, "timeout") || 
		   strings.Contains(errStr, "connection reset") || 
		   strings.Contains(errStr, "temporary failure") {
			if attempt == maxRetries-1 {
				return err
			}
			delay := time.Duration(math.Pow(2, float64(attempt))) * baseDelay
			if delay > maxDelay {
				delay = maxDelay
			}
			log.Printf("âš ï¸ ì¼ì‹œì  ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ (ì‹œë„ %d/%d): %v - %v í›„ ì¬ì‹œë„", attempt+1, maxRetries, err, delay)
			time.Sleep(delay)
			continue
		}

		return err
	}

	return fmt.Errorf("ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
}

func (ds *DriveService) DownloadFileContent(fileID string) ([]byte, error) {
	var content []byte
	err := ds.retryWithBackoff(func() error {
		resp, err := ds.service.Files.Get(fileID).Download()
		if err != nil {
			return fmt.Errorf("íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: %v", err)
		}
		defer resp.Body.Close()

		content, err = io.ReadAll(resp.Body)
		if err != nil {
			return fmt.Errorf("íŒŒì¼ ë‚´ìš© ì½ê¸° ì˜¤ë¥˜: %v", err)
		}
		return nil
	})

	return content, err
}

func calculateHash(content []byte) string {
	hash := sha256.Sum256(content)
	return fmt.Sprintf("%x", hash)
}

// íŒŒì¼ IDë¡œë¶€í„° íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ í•´ì‹œë¥¼ ê³„ì‚°í•˜ëŠ” ë©”ì„œë“œ (ìµœì í™” ë²„ì „)
func (ds *DriveService) calculateFileHash(fileID string) (string, error) {
	return ds.calculateFileHashWithRetry(fileID, 3)
}

func (ds *DriveService) calculateFileHashWithRetry(fileID string, maxRetries int) (string, error) {
	var lastErr error
	
	for attempt := 1; attempt <= maxRetries; attempt++ {
		hash, err := ds.calculateFileHashOnce(fileID)
		if err == nil {
			return hash, nil
		}
		
		lastErr = err
		if attempt < maxRetries {
			// ì§€ìˆ˜ ë°±ì˜¤í”„: 1ì´ˆ, 2ì´ˆ, 4ì´ˆ ëŒ€ê¸°
			waitTime := time.Duration(attempt) * time.Second
			log.Printf("ğŸ”„ í•´ì‹œ ê³„ì‚° ì¬ì‹œë„ %d/%d (%s): %v, %v ëŒ€ê¸°", attempt, maxRetries, fileID, err, waitTime)
			time.Sleep(waitTime)
		}
	}
	
	return "", fmt.Errorf("ìµœëŒ€ ì¬ì‹œë„ í›„ ì‹¤íŒ¨: %v", lastErr)
}

func (ds *DriveService) calculateFileHashOnce(fileID string) (string, error) {
	// íŒŒì¼ ID ìœ íš¨ì„± ê²€ì¦
	if fileID == "" || len(fileID) < 10 {
		return "", fmt.Errorf("ìœ íš¨í•˜ì§€ ì•Šì€ íŒŒì¼ ID: %s", fileID)
	}
	
	log.Printf("ğŸ” í•´ì‹œ ê³„ì‚° ì‹œì‘: %s", fileID)
	
	// Google Drive APIë¥¼ í†µí•´ íŒŒì¼ ë‚´ìš© ë‹¤ìš´ë¡œë“œ (íƒ€ì„ì•„ì›ƒ ì—†ìŒ)
	resp, err := ds.service.Files.Get(fileID).Download()
	if err != nil {
		return "", fmt.Errorf("íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: %v", err)
	}
	defer resp.Body.Close()
	
	// ê°„ë‹¨í•œ í•´ì‹œ ê³„ì‚°
	hasher := sha256.New()
	
	// io.Copyë¥¼ ì‚¬ìš©í•œ ê°„ë‹¨í•œ ë³µì‚¬
	_, err = io.Copy(hasher, resp.Body)
	if err != nil {
		return "", fmt.Errorf("íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: %v", err)
	}
	
	log.Printf("âœ… í•´ì‹œ ê³„ì‚° ì™„ë£Œ: %s", fileID)
	return fmt.Sprintf("%x", hasher.Sum(nil)), nil
}

// ì¤‘ë³µ ê·¸ë£¹ì„ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì œê±°
func (ds *DriveService) removeDuplicateGroup(groupHash string) error {
	if groupHash == "" {
		return fmt.Errorf("ê·¸ë£¹ í•´ì‹œê°€ í•„ìš”í•©ë‹ˆë‹¤")
	}

	log.Printf("ğŸ—‘ï¸ ì¤‘ë³µ ê·¸ë£¹ ì œê±° ìš”ì²­: %s", groupHash)

	// í•´ë‹¹ í•´ì‹œë¥¼ ê°€ì§„ ëª¨ë“  íŒŒì¼ì„ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‚­ì œ
	query := `DELETE FROM files WHERE hash = ?`
	result, err := ds.db.Exec(query, groupHash)
	if err != nil {
		return fmt.Errorf("ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¤‘ë³µ ê·¸ë£¹ ì‚­ì œ ì‹¤íŒ¨: %v", err)
	}

	rowsAffected, err := result.RowsAffected()
	if err != nil {
		log.Printf("âš ï¸ ì‚­ì œëœ í–‰ ìˆ˜ í™•ì¸ ì‹¤íŒ¨: %v", err)
	} else {
		log.Printf("âœ… ì¤‘ë³µ ê·¸ë£¹ ì œê±° ì™„ë£Œ: %dê°œ íŒŒì¼ ì œê±°ë¨", rowsAffected)
	}

	return nil
}

// ì‚­ì œëœ íŒŒì¼ë“¤ì„ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì •ë¦¬
func (ds *DriveService) cleanupDeletedFiles() (int, error) {
	log.Printf("ğŸ§¹ ì‚­ì œëœ íŒŒì¼ ì •ë¦¬ ì‹œì‘...")

	// ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ëª¨ë“  íŒŒì¼ ID ê°€ì ¸ì˜¤ê¸°
	query := `SELECT id, name FROM files`
	rows, err := ds.db.Query(query)
	if err != nil {
		return 0, fmt.Errorf("íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: %v", err)
	}
	defer rows.Close()

	var filesToCheck []struct {
		ID   string
		Name string
	}

	for rows.Next() {
		var file struct {
			ID   string
			Name string
		}
		if err := rows.Scan(&file.ID, &file.Name); err != nil {
			log.Printf("âš ï¸ íŒŒì¼ ì •ë³´ ìŠ¤ìº” ì‹¤íŒ¨: %v", err)
			continue
		}
		filesToCheck = append(filesToCheck, file)
	}

	log.Printf("ğŸ“Š ì´ %dê°œ íŒŒì¼ í™•ì¸ ì¤‘...", len(filesToCheck))

	deletedCount := 0
	for i, file := range filesToCheck {
		if i%100 == 0 {
			log.Printf("ğŸ“‹ ì§„í–‰ë¥ : %d/%d (%dê°œ ì‚­ì œë¨)", i, len(filesToCheck), deletedCount)
		}

		// Google Drive APIë¡œ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
		_, err := ds.service.Files.Get(file.ID).Fields("id,trashed").Do()
		if err != nil {
			// íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°
			log.Printf("âŒ ì‚­ì œëœ íŒŒì¼ ë°œê²¬: %s (%s)", file.Name, file.ID)
			
			// ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì œê±°
			deleteErr := ds.deleteFileFromDB(file.ID)
			if deleteErr != nil {
				log.Printf("âš ï¸ DBì—ì„œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: %v", deleteErr)
			} else {
				deletedCount++
			}
		}
	}

	log.Printf("âœ… ì‚­ì œëœ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ: %dê°œ íŒŒì¼ ì œê±°ë¨", deletedCount)
	return deletedCount, nil
}

// ë¹ˆ í´ë”ì¸ì§€ í™•ì¸
func (ds *DriveService) isFolderEmpty(folderID string) (bool, error) {
	query := fmt.Sprintf("'%s' in parents and trashed=false", folderID)
	listCall := ds.service.Files.List().
		Q(query).
		Fields("files(id)").
		PageSize(1) // í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ë¹ˆ í´ë”ê°€ ì•„ë‹˜

	response, err := listCall.Do()
	if err != nil {
		return false, fmt.Errorf("í´ë” ë‚´ìš© í™•ì¸ ì‹¤íŒ¨: %v", err)
	}

	return len(response.Files) == 0, nil
}

// í´ë” ì‚­ì œ
func (ds *DriveService) deleteFolder(folderID string) error {
	// í´ë” ì •ë³´ ë¨¼ì € ê°€ì ¸ì˜¤ê¸°
	folderInfo, err := ds.service.Files.Get(folderID).Fields("id,name,parents").Do()
	if err != nil {
		return fmt.Errorf("í´ë” ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: %v", err)
	}

	log.Printf("ğŸ—‘ï¸ ë¹ˆ í´ë” ì‚­ì œ: %s (%s)", folderInfo.Name, folderID)

	// í´ë” ì‚­ì œ
	err = ds.service.Files.Delete(folderID).Do()
	if err != nil {
		return fmt.Errorf("í´ë” ì‚­ì œ ì‹¤íŒ¨: %v", err)
	}

	log.Printf("âœ… í´ë” ì‚­ì œ ì™„ë£Œ: %s", folderInfo.Name)

	// ìƒìœ„ í´ë”ë„ ë¹ˆ í´ë”ì¸ì§€ ì¬ê·€ì ìœ¼ë¡œ í™•ì¸
	if len(folderInfo.Parents) > 0 {
		parentFolderID := folderInfo.Parents[0]
		return ds.checkAndDeleteEmptyFolder(parentFolderID)
	}

	return nil
}

// í´ë”ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì‚­ì œí•˜ê³  ìƒìœ„ í´ë”ë„ ì¬ê·€ì ìœ¼ë¡œ í™•ì¸
func (ds *DriveService) checkAndDeleteEmptyFolder(folderID string) error {
	// ë£¨íŠ¸ í´ë”ë‚˜ íŠ¹ìˆ˜ í´ë”ëŠ” ì‚­ì œí•˜ì§€ ì•ŠìŒ
	if folderID == "" || folderID == "root" {
		return nil
	}

	// í´ë” ì •ë³´ í™•ì¸
	folderInfo, err := ds.service.Files.Get(folderID).Fields("id,name,mimeType,parents").Do()
	if err != nil {
		// í´ë”ê°€ ì´ë¯¸ ì‚­ì œë˜ì—ˆê±°ë‚˜ ì ‘ê·¼í•  ìˆ˜ ì—†ëŠ” ê²½ìš°
		log.Printf("âš ï¸ í´ë” ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ (%s): %v", folderID, err)
		return nil
	}

	// í´ë”ê°€ ì•„ë‹Œ ê²½ìš° ê±´ë„ˆë›°ê¸°
	if folderInfo.MimeType != "application/vnd.google-apps.folder" {
		return nil
	}

	// ë¹ˆ í´ë”ì¸ì§€ í™•ì¸
	isEmpty, err := ds.isFolderEmpty(folderID)
	if err != nil {
		log.Printf("âš ï¸ í´ë” ë¹ˆ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨ (%s): %v", folderInfo.Name, err)
		return nil
	}

	if isEmpty {
		log.Printf("ğŸ“‚ ë¹ˆ í´ë” ë°œê²¬: %s (%s)", folderInfo.Name, folderID)
		
		// í´ë” ì‚­ì œ
		err = ds.service.Files.Delete(folderID).Do()
		if err != nil {
			log.Printf("âš ï¸ í´ë” ì‚­ì œ ì‹¤íŒ¨ (%s): %v", folderInfo.Name, err)
			return nil
		}

		log.Printf("âœ… ë¹ˆ í´ë” ì‚­ì œ ì™„ë£Œ: %s", folderInfo.Name)

		// ìƒìœ„ í´ë”ë„ ë¹ˆ í´ë”ì¸ì§€ ì¬ê·€ì ìœ¼ë¡œ í™•ì¸
		if len(folderInfo.Parents) > 0 {
			return ds.checkAndDeleteEmptyFolder(folderInfo.Parents[0])
		}
	}

	return nil
}

// íŒŒì¼ ì‚­ì œ í›„ ìƒìœ„ í´ë”ë“¤ì˜ ë¹ˆ ìƒíƒœ í™•ì¸ ë° ì‚­ì œ
func (ds *DriveService) cleanupEmptyFoldersAfterFileDeletion(fileID string) error {
	// ì‚­ì œëœ íŒŒì¼ì˜ ìƒìœ„ í´ë” ì •ë³´ ì¡°íšŒ
	fileInfo, err := ds.service.Files.Get(fileID).Fields("id,name,parents").Do()
	if err != nil {
		// íŒŒì¼ì´ ì´ë¯¸ ì‚­ì œë˜ì—ˆìœ¼ë¯€ë¡œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìƒìœ„ í´ë” ì •ë³´ë¥¼ ê°€ì ¸ì™€ì•¼ í•¨
		log.Printf("âš ï¸ ì‚­ì œëœ íŒŒì¼ì˜ ìƒìœ„ í´ë” í™•ì¸ ë¶ˆê°€: %s", fileID)
		return nil
	}

	// ìƒìœ„ í´ë”ê°€ ìˆìœ¼ë©´ ë¹ˆ í´ë”ì¸ì§€ í™•ì¸
	if len(fileInfo.Parents) > 0 {
		return ds.checkAndDeleteEmptyFolder(fileInfo.Parents[0])
	}

	return nil
}

// ì „ì²´ ë“œë¼ì´ë¸Œì—ì„œ ë¹ˆ í´ë”ë“¤ì„ ì°¾ì•„ì„œ ì •ë¦¬
func (ds *DriveService) cleanupAllEmptyFolders() (int, error) {
	log.Printf("ğŸ“‚ ì „ì²´ ë“œë¼ì´ë¸Œ ë¹ˆ í´ë” ì •ë¦¬ ì‹œì‘...")

	// ëª¨ë“  í´ë” ì¡°íšŒ
	query := "mimeType='application/vnd.google-apps.folder' and trashed=false"
	var allFolders []*drive.File
	pageToken := ""

	for {
		listCall := ds.service.Files.List().
			Q(query).
			Fields("nextPageToken, files(id, name, parents)").
			PageSize(1000)

		if pageToken != "" {
			listCall = listCall.PageToken(pageToken)
		}

		response, err := listCall.Do()
		if err != nil {
			return 0, fmt.Errorf("í´ë” ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: %v", err)
		}

		allFolders = append(allFolders, response.Files...)

		pageToken = response.NextPageToken
		if pageToken == "" {
			break
		}
	}

	log.Printf("ğŸ“Š ì´ %dê°œ í´ë” í™•ì¸ ì¤‘...", len(allFolders))

	deletedCount := 0
	
	// í•˜ìœ„ í´ë”ë¶€í„° ì •ë¦¬í•˜ê¸° ìœ„í•´ ì—­ìˆœìœ¼ë¡œ ì²˜ë¦¬
	for i := len(allFolders) - 1; i >= 0; i-- {
		folder := allFolders[i]
		
		if i%100 == 0 {
			log.Printf("ğŸ“‹ ì§„í–‰ë¥ : %d/%d (%dê°œ ì‚­ì œë¨)", len(allFolders)-i, len(allFolders), deletedCount)
		}

		// ë£¨íŠ¸ í´ë”ë‚˜ íŠ¹ìˆ˜ í´ë”ëŠ” ê±´ë„ˆë›°ê¸°
		if folder.Id == "root" || len(folder.Parents) == 0 {
			continue
		}

		// ë¹ˆ í´ë”ì¸ì§€ í™•ì¸
		isEmpty, err := ds.isFolderEmpty(folder.Id)
		if err != nil {
			log.Printf("âš ï¸ í´ë” ë¹ˆ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨ (%s): %v", folder.Name, err)
			continue
		}

		if isEmpty {
			log.Printf("ğŸ“‚ ë¹ˆ í´ë” ë°œê²¬: %s (%s)", folder.Name, folder.Id)
			
			// í´ë” ì‚­ì œ
			err = ds.service.Files.Delete(folder.Id).Do()
			if err != nil {
				log.Printf("âš ï¸ í´ë” ì‚­ì œ ì‹¤íŒ¨ (%s): %v", folder.Name, err)
				continue
			}

			log.Printf("âœ… ë¹ˆ í´ë” ì‚­ì œ ì™„ë£Œ: %s", folder.Name)
			deletedCount++

			// API ì œí•œì„ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
			time.Sleep(200 * time.Millisecond)
		}
	}

	log.Printf("âœ… ë¹ˆ í´ë” ì •ë¦¬ ì™„ë£Œ: %dê°œ í´ë” ì‚­ì œë¨", deletedCount)
	return deletedCount, nil
}

// ëŒ€ìƒ í´ë” ì „ì²´ ì‚­ì œ (ì¤‘ë³µ ë¹„êµ í›„)
func (ds *DriveService) deleteTargetFolder(folderID, folderName string) error {
	log.Printf("ğŸ—‘ï¸ ëŒ€ìƒ í´ë” ì‚­ì œ ì‹œì‘: %s (%s)", folderName, folderID)

	// í´ë” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
	folderInfo, err := ds.service.Files.Get(folderID).Fields("id,name,trashed").Do()
	if err != nil {
		return fmt.Errorf("í´ë” ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: %v", err)
	}

	if folderInfo.Trashed {
		return fmt.Errorf("í´ë”ê°€ ì´ë¯¸ íœ´ì§€í†µì— ìˆìŠµë‹ˆë‹¤: %s", folderName)
	}

	// í´ë” ë‚´ìš© í™•ì¸ (ë§ˆì§€ë§‰ ì•ˆì „ í™•ì¸)
	query := fmt.Sprintf("'%s' in parents and trashed=false", folderID)
	listCall := ds.service.Files.List().
		Q(query).
		Fields("files(id,name,mimeType)").
		PageSize(10) // ëª‡ ê°œë§Œ í™•ì¸

	response, err := listCall.Do()
	if err != nil {
		return fmt.Errorf("í´ë” ë‚´ìš© í™•ì¸ ì‹¤íŒ¨: %v", err)
	}

	log.Printf("ğŸ“‚ í´ë” '%s'ì— %dê°œ í•­ëª© í™•ì¸ë¨", folderName, len(response.Files))

	// ë¹ˆ í´ë”ê°€ ì•„ë‹Œ ê²½ìš° ê²½ê³  (í•˜ì§€ë§Œ ê³„ì† ì§„í–‰)
	if len(response.Files) > 0 {
		log.Printf("âš ï¸ ì£¼ì˜: í´ë” '%s'ì— %dê°œ íŒŒì¼/í´ë”ê°€ ìˆìŠµë‹ˆë‹¤. ëª¨ë‘ ì‚­ì œë©ë‹ˆë‹¤.", folderName, len(response.Files))
	}

	// í´ë” ì‚­ì œ ì‹¤í–‰
	err = ds.service.Files.Delete(folderID).Do()
	if err != nil {
		return fmt.Errorf("í´ë” ì‚­ì œ ì‹¤íŒ¨: %v", err)
	}

	log.Printf("âœ… ëŒ€ìƒ í´ë” ì‚­ì œ ì™„ë£Œ: %s", folderName)
	return nil
}

// ë³‘ë ¬ í•´ì‹œ ê³„ì‚°ì„ ìœ„í•œ êµ¬ì¡°ì²´
type hashJob struct {
	file   *DriveFile
	result chan hashResult
}

type hashResult struct {
	fileID string
	hash   string
	err    error
}

// ë³‘ë ¬ í•´ì‹œ ê³„ì‚° (ìµœì í™”ëœ ì›Œì»¤ í’€ íŒ¨í„´)
func (ds *DriveService) calculateHashesInParallel(files []*DriveFile, maxWorkers int) error {
	if len(files) == 0 {
		return nil
	}
	
	// ìµœì í™”ëœ ì›Œì»¤ ìˆ˜ ê³„ì‚° (ë„ˆë¬´ ë§ìœ¼ë©´ ì˜¤íˆë ¤ ëŠë ¤ì§)
	optimalWorkers := maxWorkers
	if maxWorkers > 8 && len(files) < maxWorkers*4 {
		optimalWorkers = max(4, len(files)/4)
		log.Printf("âš™ï¸ ì›Œì»¤ ìˆ˜ ìµœì í™”: %d -> %d (íŒŒì¼ ìˆ˜ ëŒ€ë¹„ ì¡°ì •)", maxWorkers, optimalWorkers)
	}
	
	// íŒŒì¼ ìœ íš¨ì„± ì¬ê²€ì¦
	var validFiles []*DriveFile
	for _, file := range files {
		if file.ID != "" && len(file.ID) > 10 && file.Size > 0 {
			validFiles = append(validFiles, file)
		} else {
			log.Printf("âš ï¸ í•´ì‹œ ê³„ì‚°ì—ì„œ ìœ íš¨í•˜ì§€ ì•Šì€ íŒŒì¼ ì œì™¸: ID=%s, Size=%d", file.ID, file.Size)
		}
	}
	
	if len(validFiles) != len(files) {
		log.Printf("ğŸ“‹ íŒŒì¼ ìœ íš¨ì„± ê²€ì¦: %dê°œ â†’ %dê°œ íŒŒì¼ë¡œ í•„í„°ë§ë¨", len(files), len(validFiles))
		files = validFiles
	}
	
	log.Printf("ğŸš€ ìµœì í™”ëœ ë³‘ë ¬ í•´ì‹œ ê³„ì‚° ì‹œì‘: %dê°œ ê²€ì¦ëœ íŒŒì¼, %dê°œ ì›Œì»¤", len(files), optimalWorkers)
	
	// ì±„ë„ ë²„í¼ í¬ê¸° ìµœì í™”
	jobs := make(chan hashJob, min(optimalWorkers*3, 1000))
	results := make(chan hashResult, optimalWorkers*2)
	
	// ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
	startTime := time.Now()
	
	// ì›Œì»¤ ì‹œì‘
	var wg sync.WaitGroup
	for w := 0; w < optimalWorkers; w++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()
			localCount := 0
			localStart := time.Now()
			
			for job := range jobs {
				hash, err := ds.calculateFileHash(job.file.ID)
				results <- hashResult{
					fileID: job.file.ID,
					hash:   hash,
					err:    err,
				}
				
				localCount++
				// ì›Œì»¤ë³„ ì„±ëŠ¥ ë¡œê¹… (50ê°œë§ˆë‹¤)
				if localCount%50 == 0 {
					elapsed := time.Since(localStart)
					rate := float64(localCount) / elapsed.Seconds()
					log.Printf("ğŸ“Š ì›Œì»¤ %d: %dê°œ ì²˜ë¦¬, ì†ë„: %.1f/s", workerID, localCount, rate)
				}
			}
			
			elapsed := time.Since(localStart)
			rate := float64(localCount) / elapsed.Seconds()
			log.Printf("âœ… ì›Œì»¤ %d ì™„ë£Œ: %dê°œ ì²˜ë¦¬, í‰ê·  %.1f/s", workerID, localCount, rate)
		}(w)
	}
	
	// ì‘ì—… íì— ì¶”ê°€
	go func() {
		defer close(jobs)
		for i, file := range files {
			jobs <- hashJob{file: file}
			
			// í ì§„í–‰ ìƒí™© ë¡œê¹… (1000ê°œë§ˆë‹¤)
			if i > 0 && i%1000 == 0 {
				log.Printf("ğŸ“¤ í ì§„í–‰: %d/%dê°œ ì¶”ê°€ë¨", i+1, len(files))
			}
		}
		log.Printf("ğŸ“¤ ëª¨ë“  ì‘ì—…ì´ íì— ì¶”ê°€ë¨: %dê°œ", len(files))
	}()
	
	// ì›Œì»¤ ì™„ë£Œ ëŒ€ê¸°
	go func() {
		wg.Wait()
		close(results)
	}()
	
	// ê²°ê³¼ ìˆ˜ì§‘
	hashMap := make(map[string]string)
	completedCount := 0
	lastUpdateTime := time.Now()
	var failCount int
	
	for result := range results {
		completedCount++
		
		if result.err != nil {
			failCount++
			log.Printf("âš ï¸ í•´ì‹œ ê³„ì‚° ì‹¤íŒ¨ (%s): %v", result.fileID, result.err)
			continue
		}
		
		hashMap[result.fileID] = result.hash
		
		// ìµœì í™”ëœ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ (5ì´ˆë§ˆë‹¤ ë˜ëŠ” 20ê°œë§ˆë‹¤)
		now := time.Now()
		if completedCount%20 == 0 || now.Sub(lastUpdateTime) >= 5*time.Second {
			percentage := float64(completedCount) / float64(len(files)) * 100
			elapsed := time.Since(startTime)
			rate := float64(completedCount) / elapsed.Seconds()
			
			var eta string
			if rate > 0 {
				etaSeconds := float64(len(files)-completedCount) / rate
				eta = time.Duration(etaSeconds * float64(time.Second)).Round(time.Second).String()
			} else {
				eta = "ê³„ì‚° ì¤‘..."
			}
			
			updateComparisonProgress(func(p *FolderComparisonProgress) {
				p.HashesCalculated = len(hashMap)
				p.CurrentStep = fmt.Sprintf("í•´ì‹œ ê³„ì‚° ì¤‘... (%d/%d, %.1f%%, %.1f/s, ETA: %s)", 
					completedCount, len(files), percentage, rate, eta)
			})
			
			log.Printf("ğŸ“ˆ ì§„í–‰: %d/%d (%.1f%%), ì„±ê³µ: %d, ì‹¤íŒ¨: %d, ì†ë„: %.1f/s, ì˜ˆìƒì™„ë£Œ: %s", 
				completedCount, len(files), percentage, len(hashMap), failCount, rate, eta)
			lastUpdateTime = now
		}
	}
	
	// íŒŒì¼ ê°ì²´ì— í•´ì‹œ í• ë‹¹
	successCount := 0
	for _, file := range files {
		if hash, exists := hashMap[file.ID]; exists {
			file.Hash = hash
			successCount++
		}
	}
	
	// ìµœì¢… í†µê³„
	elapsed := time.Since(startTime)
	avgRate := float64(completedCount) / elapsed.Seconds()
	
	// ìµœì¢… ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
	updateComparisonProgress(func(p *FolderComparisonProgress) {
		p.HashesCalculated = successCount
		p.CurrentStep = fmt.Sprintf("í•´ì‹œ ê³„ì‚° ì™„ë£Œ (%d ì„±ê³µ, %d ì‹¤íŒ¨, í‰ê·  %.1f/s)", 
			successCount, failCount, avgRate)
	})
	
	log.Printf("ğŸ ë³‘ë ¬ í•´ì‹œ ê³„ì‚° ì™„ë£Œ!")
	log.Printf("ğŸ“Š ì´ %dê°œ íŒŒì¼ ì¤‘ %dê°œ ì„±ê³µ, %dê°œ ì‹¤íŒ¨", len(files), successCount, failCount)
	log.Printf("â±ï¸ ì´ ì†Œìš”ì‹œê°„: %v, í‰ê·  ì†ë„: %.2f íŒŒì¼/ì´ˆ", elapsed, avgRate)
	
	if avgRate < 1.0 {
		log.Printf("ğŸ’¡ ì„±ëŠ¥ íŒ: ì›Œì»¤ ìˆ˜ë¥¼ ì¤„ì´ê±°ë‚˜ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•´ë³´ì„¸ìš”")
	}
	
	return nil
}

// min í•¨ìˆ˜ (Go 1.18 ì´ì „ ë²„ì „ í˜¸í™˜ì„±)
func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

// max í•¨ìˆ˜ (Go 1.18 ì´ì „ ë²„ì „ í˜¸í™˜ì„±)
func max(a, b int) int {
	if a > b {
		return a
	}
	return b
}

// í´ë” ì´ë¦„ ìºì‹œ
var folderCache = make(map[string]string)
var folderCacheMutex sync.RWMutex

func (ds *DriveService) getFilePath(fileID string, parents []string) string {
	if len(parents) == 0 {
		return "/"
	}
	
	return ds.buildFullPath(parents[0])
}

// í´ë” ì •ë³´ êµ¬ì¡°ì²´ (ìºì‹œìš©)
type FolderInfo struct {
	Name     string
	Parents  []string
}

// í´ë” ìºì‹œ (ì´ë¦„ê³¼ ë¶€ëª¨ ì •ë³´ ëª¨ë‘ í¬í•¨)
var folderInfoCache = make(map[string]*FolderInfo)

func (ds *DriveService) buildFullPath(folderID string) string {
	log.Printf("ğŸ” ê²½ë¡œ êµ¬ì„± ì‹œì‘: í´ë” ID %s", folderID)
	
	if folderID == "root" || folderID == "0AEBGrCpGtL_PUk9PVA" {
		log.Printf("ğŸ“ ë£¨íŠ¸ í´ë” ê°ì§€: %s -> /", folderID)
		return "/"
	}
	
	// ìºì‹œì—ì„œ í´ë” ì •ë³´ í™•ì¸
	folderCacheMutex.RLock()
	if folderInfo, exists := folderInfoCache[folderID]; exists {
		folderCacheMutex.RUnlock()
		log.Printf("ğŸ“‹ ìºì‹œì—ì„œ í´ë” ì •ë³´ ë°œê²¬: %s (ë¶€ëª¨: %v)", folderInfo.Name, folderInfo.Parents)
		// ë¶€ëª¨ í´ë” ê²½ë¡œ ì¬ê·€ì ìœ¼ë¡œ êµ¬ì„±
		if len(folderInfo.Parents) > 0 {
			parentPath := ds.buildFullPath(folderInfo.Parents[0])
			if parentPath == "/" {
				result := "/" + folderInfo.Name
				log.Printf("ğŸ“ ê²½ë¡œ ì™„ì„± (ë£¨íŠ¸ í•˜ìœ„): %s", result)
				return result
			}
			result := parentPath + "/" + folderInfo.Name
			log.Printf("ğŸ“ ê²½ë¡œ ì™„ì„± (ì¤‘ì²©): %s", result)
			return result
		}
		result := "/" + folderInfo.Name
		log.Printf("ğŸ“ ê²½ë¡œ ì™„ì„± (ë¶€ëª¨ ì—†ìŒ): %s", result)
		return result
	}
	folderCacheMutex.RUnlock()
	
	// ìºì‹œì— ì—†ìœ¼ë©´ API í˜¸ì¶œ
	log.Printf("ğŸŒ API í˜¸ì¶œë¡œ í´ë” ì •ë³´ ì¡°íšŒ: %s", folderID)
	folder, err := ds.service.Files.Get(folderID).Fields("id, name, parents").Do()
	if err != nil {
		log.Printf("âš ï¸ í´ë” ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ (ID: %s): %v", folderID, err)
		return "/"
	}
	
	log.Printf("ğŸ“‹ API ì‘ë‹µ: ì´ë¦„='%s', ë¶€ëª¨=%v", folder.Name, folder.Parents)
	
	// ìºì‹œì— ì €ì¥ (ì´ë¦„ê³¼ ë¶€ëª¨ ì •ë³´ ëª¨ë‘)
	folderCacheMutex.Lock()
	folderCache[folderID] = folder.Name // ê¸°ì¡´ ìºì‹œ í˜¸í™˜ì„±
	folderInfoCache[folderID] = &FolderInfo{
		Name:    folder.Name,
		Parents: folder.Parents,
	}
	folderCacheMutex.Unlock()
	
	// ë¶€ëª¨ í´ë” ê²½ë¡œ ì¬ê·€ì ìœ¼ë¡œ êµ¬ì„±
	if len(folder.Parents) > 0 {
		parentPath := ds.buildFullPath(folder.Parents[0])
		if parentPath == "/" {
			result := "/" + folder.Name
			log.Printf("ğŸ“ ê²½ë¡œ ì™„ì„± (ë£¨íŠ¸ í•˜ìœ„): %s", result)
			return result
		}
		result := parentPath + "/" + folder.Name
		log.Printf("ğŸ“ ê²½ë¡œ ì™„ì„± (ì¤‘ì²©): %s", result)
		return result
	}
	
	result := "/" + folder.Name
	log.Printf("ğŸ“ ê²½ë¡œ ì™„ì„± (ë¶€ëª¨ ì—†ìŒ): %s", result)
	return result
}

// ì¤‘ë³µ íŒŒì¼ë“¤ì˜ ê²½ë¡œë¥¼ ê°„ë‹¨íˆ ì„¤ì • (ì‹¤ì‹œê°„ í‘œì‹œë¥¼ ìœ„í•´)
func (ds *DriveService) enrichDuplicatesWithPaths(duplicates [][]*DriveFile) [][]*DriveFile {
	log.Println("ğŸ“ ì¤‘ë³µ íŒŒì¼ ê²½ë¡œ ì„¤ì • ì¤‘...")
	
	for _, group := range duplicates {
		for _, file := range group {
			// ê²½ë¡œê°€ ë¹„ì–´ìˆìœ¼ë©´ "ê²½ë¡œ ë¯¸í™•ì¸"ìœ¼ë¡œ í‘œì‹œ
			if file.Path == "" || file.Path == "/" {
				file.Path = "ê²½ë¡œ ë¯¸í™•ì¸"
			}
		}
	}
	
	log.Println("âœ… ì¤‘ë³µ íŒŒì¼ ê¸°ë³¸ ê²½ë¡œ ì„¤ì • ì™„ë£Œ")
	return duplicates
}

// ë°ì´í„°ë² ì´ìŠ¤ì˜ ëª¨ë“  íŒŒì¼ì— parents ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” í•¨ìˆ˜
func (ds *DriveService) updateAllFileParents() error {
	log.Println("ğŸ”„ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ë“¤ì˜ parents ì •ë³´ ì—…ë°ì´íŠ¸ ì‹œì‘...")
	
	// parents ì •ë³´ê°€ ì—†ëŠ” íŒŒì¼ë“¤ ì¡°íšŒ
	rows, err := ds.db.Query("SELECT id, name FROM files WHERE parents IS NULL OR parents = ''")
	if err != nil {
		return fmt.Errorf("íŒŒì¼ ì¡°íšŒ ì˜¤ë¥˜: %v", err)
	}
	defer rows.Close()
	
	var filesToUpdate []struct {
		ID   string
		Name string
	}
	
	for rows.Next() {
		var file struct {
			ID   string
			Name string
		}
		if err := rows.Scan(&file.ID, &file.Name); err != nil {
			continue
		}
		filesToUpdate = append(filesToUpdate, file)
	}
	
	log.Printf("ğŸ“Š ì—…ë°ì´íŠ¸í•  íŒŒì¼ ìˆ˜: %dê°œ", len(filesToUpdate))
	
	// ë°°ì¹˜ í¬ê¸° ì œí•œ
	batchSize := 50
	for i := 0; i < len(filesToUpdate); i += batchSize {
		end := i + batchSize
		if end > len(filesToUpdate) {
			end = len(filesToUpdate)
		}
		
		log.Printf("ğŸ”„ ë°°ì¹˜ %d-%d ì²˜ë¦¬ ì¤‘...", i+1, end)
		
		for j := i; j < end; j++ {
			file := filesToUpdate[j]
			
			// APIì—ì„œ parents ì •ë³´ ì¡°íšŒ
			fileInfo, err := ds.service.Files.Get(file.ID).Fields("id, name, parents").Do()
			if err != nil {
				log.Printf("âš ï¸ íŒŒì¼ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: %s", file.Name)
				continue
			}
			
			// parents ì •ë³´ ì—…ë°ì´íŠ¸
			parentsJSON, _ := json.Marshal(fileInfo.Parents)
			_, err = ds.db.Exec("UPDATE files SET parents = ? WHERE id = ?", string(parentsJSON), file.ID)
			if err != nil {
				log.Printf("âš ï¸ íŒŒì¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: %s", file.Name)
			}
		}
		
		// API ì œí•œì„ ìœ„í•œ ëŒ€ê¸°
		time.Sleep(time.Second)
	}
	
	log.Println("âœ… parents ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
	return nil
}

// íŠ¹ì • í´ë”ì˜ íŒŒì¼ë“¤ì„ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ í•„í„°ë§í•˜ì—¬ ê²€ìƒ‰
func (ds *DriveService) searchFilesInFolder(folderID, regexPattern string) ([]*DriveFile, error) {
	log.Printf("ğŸ” í´ë” %sì—ì„œ íŒ¨í„´ '%s'ì— ë§ëŠ” íŒŒì¼ ê²€ìƒ‰ ì¤‘...", folderID, regexPattern)
	
	// ì •ê·œí‘œí˜„ì‹ ì»´íŒŒì¼
	regex, err := regexp.Compile(regexPattern)
	if err != nil {
		return nil, fmt.Errorf("ì˜ëª»ëœ ì •ê·œí‘œí˜„ì‹: %v", err)
	}
	
	var allFiles []*DriveFile
	pageToken := ""
	
	for {
		query := fmt.Sprintf("'%s' in parents and trashed=false", folderID)
		
		result, err := ds.service.Files.List().
			Q(query).
			PageSize(1000).
			PageToken(pageToken).
			Fields("nextPageToken, files(id, name, size, webViewLink, mimeType, modifiedTime, parents)").
			Do()
			
		if err != nil {
			return nil, fmt.Errorf("í´ë” íŒŒì¼ ì¡°íšŒ ì˜¤ë¥˜: %v", err)
		}
		
		for _, file := range result.Files {
			// ì •ê·œí‘œí˜„ì‹ê³¼ ë§¤ì¹˜ë˜ëŠ” íŒŒì¼ë§Œ ì¶”ê°€
			if regex.MatchString(file.Name) {
				driveFile := &DriveFile{
					ID:           file.Id,
					Name:         file.Name,
					Size:         file.Size,
					WebViewLink:  file.WebViewLink,
					MimeType:     file.MimeType,
					ModifiedTime: file.ModifiedTime,
					Parents:      file.Parents,
				}
				allFiles = append(allFiles, driveFile)
			}
		}
		
		pageToken = result.NextPageToken
		if pageToken == "" {
			break
		}
	}
	
	log.Printf("âœ… ì´ %dê°œ íŒŒì¼ì´ íŒ¨í„´ê³¼ ì¼ì¹˜í•¨", len(allFiles))
	return allFiles, nil
}

// ì—¬ëŸ¬ íŒŒì¼ì„ ì¼ê´„ ì‚­ì œ
func (ds *DriveService) bulkDeleteFiles(fileIDs []string) (int, error) {
	log.Printf("ğŸ—‘ï¸ %dê°œ íŒŒì¼ ì¼ê´„ ì‚­ì œ ì‹œì‘...", len(fileIDs))
	
	deletedCount := 0
	var parentFoldersToCheck []string
	
	for i, fileID := range fileIDs {
		log.Printf("ì‚­ì œ ì¤‘ (%d/%d): %s", i+1, len(fileIDs), fileID)
		
		// íŒŒì¼ ì‚­ì œ ì „ì— ìƒìœ„ í´ë” ì •ë³´ ì €ì¥
		fileInfo, err := ds.service.Files.Get(fileID).Fields("id,name,parents").Do()
		if err != nil {
			log.Printf("âš ï¸ íŒŒì¼ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ (%s): %v", fileID, err)
		} else {
			// ìƒìœ„ í´ë”ë“¤ì„ ë‚˜ì¤‘ì— í™•ì¸í•  ëª©ë¡ì— ì¶”ê°€
			for _, parentID := range fileInfo.Parents {
				// ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ì´ë¯¸ ëª©ë¡ì— ìˆëŠ”ì§€ í™•ì¸
				found := false
				for _, existingParent := range parentFoldersToCheck {
					if existingParent == parentID {
						found = true
						break
					}
				}
				if !found {
					parentFoldersToCheck = append(parentFoldersToCheck, parentID)
				}
			}
			log.Printf("ğŸ—‘ï¸ íŒŒì¼ ì‚­ì œ: %s (%s)", fileInfo.Name, fileID)
		}
		
		err = ds.service.Files.Delete(fileID).Do()
		if err != nil {
			log.Printf("âš ï¸ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: %s - %v", fileID, err)
			continue
		}
		
		// ë°ì´í„°ë² ì´ìŠ¤ì—ì„œë„ ì‚­ì œ
		ds.deleteFileFromDB(fileID)
		
		deletedCount++
		
		// API ì œí•œì„ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
		time.Sleep(100 * time.Millisecond)
	}
	
	log.Printf("âœ… ì¼ê´„ ì‚­ì œ ì™„ë£Œ: %dê°œ ì„±ê³µ, %dê°œ ì‹¤íŒ¨", deletedCount, len(fileIDs)-deletedCount)
	
	// ëª¨ë“  íŒŒì¼ ì‚­ì œ í›„ ë¹ˆ í´ë”ë“¤ ì •ë¦¬ (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰)
	if len(parentFoldersToCheck) > 0 {
		log.Printf("ğŸ“‚ ë¹ˆ í´ë” ì •ë¦¬ ì‹œì‘: %dê°œ í´ë” í™•ì¸", len(parentFoldersToCheck))
		go func() {
			for _, parentID := range parentFoldersToCheck {
				err := ds.checkAndDeleteEmptyFolder(parentID)
				if err != nil {
					log.Printf("âš ï¸ ë¹ˆ í´ë” ì •ë¦¬ ì‹¤íŒ¨: %v", err)
				}
			}
			log.Printf("âœ… ë¹ˆ í´ë” ì •ë¦¬ ì™„ë£Œ")
		}()
	}
	
	return deletedCount, nil
}

func (ds *DriveService) bulkDeleteFilesWithCleanup(fileIDs []string, cleanupEmptyFolders bool) (int, error) {
	log.Printf("ğŸ—‘ï¸ %dê°œ íŒŒì¼ ì¼ê´„ ì‚­ì œ ì‹œì‘ (ë¹ˆ í´ë” ì •ë¦¬: %v)...", len(fileIDs), cleanupEmptyFolders)
	
	deletedCount := 0
	var parentFoldersToCheck []string
	
	for i, fileID := range fileIDs {
		log.Printf("ì‚­ì œ ì¤‘ (%d/%d): %s", i+1, len(fileIDs), fileID)
		
		// ë¹ˆ í´ë” ì •ë¦¬ê°€ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ ìƒìœ„ í´ë” ì •ë³´ ì €ì¥
		if cleanupEmptyFolders {
			fileInfo, err := ds.service.Files.Get(fileID).Fields("id,name,parents").Do()
			if err != nil {
				log.Printf("âš ï¸ íŒŒì¼ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ (%s): %v", fileID, err)
			} else {
				// ìƒìœ„ í´ë”ë“¤ì„ ë‚˜ì¤‘ì— í™•ì¸í•  ëª©ë¡ì— ì¶”ê°€
				for _, parentID := range fileInfo.Parents {
					// ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ì´ë¯¸ ëª©ë¡ì— ìˆëŠ”ì§€ í™•ì¸
					found := false
					for _, existingParent := range parentFoldersToCheck {
						if existingParent == parentID {
							found = true
							break
						}
					}
					if !found {
						parentFoldersToCheck = append(parentFoldersToCheck, parentID)
					}
				}
				log.Printf("ğŸ—‘ï¸ íŒŒì¼ ì‚­ì œ: %s (%s)", fileInfo.Name, fileID)
			}
		}
		
		err := ds.service.Files.Delete(fileID).Do()
		if err != nil {
			log.Printf("âš ï¸ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: %s - %v", fileID, err)
			continue
		}
		
		// ë°ì´í„°ë² ì´ìŠ¤ì—ì„œë„ ì‚­ì œ
		ds.deleteFileFromDB(fileID)
		
		deletedCount++
		
		// API ì œí•œì„ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
		time.Sleep(100 * time.Millisecond)
	}
	
	log.Printf("âœ… ì¼ê´„ ì‚­ì œ ì™„ë£Œ: %dê°œ ì„±ê³µ, %dê°œ ì‹¤íŒ¨", deletedCount, len(fileIDs)-deletedCount)
	
	// ë¹ˆ í´ë” ì •ë¦¬ê°€ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ ì‹¤í–‰
	if cleanupEmptyFolders && len(parentFoldersToCheck) > 0 {
		log.Printf("ğŸ“‚ ë¹ˆ í´ë” ì •ë¦¬ ì‹œì‘: %dê°œ í´ë” í™•ì¸", len(parentFoldersToCheck))
		go func() {
			for _, parentID := range parentFoldersToCheck {
				err := ds.checkAndDeleteEmptyFolder(parentID)
				if err != nil {
					log.Printf("âš ï¸ ë¹ˆ í´ë” ì •ë¦¬ ì‹¤íŒ¨: %v", err)
				}
			}
			log.Printf("âœ… ë¹ˆ í´ë” ì •ë¦¬ ì™„ë£Œ")
		}()
	} else if !cleanupEmptyFolders {
		log.Printf("ğŸ“‚ ë¹ˆ í´ë” ì •ë¦¬ ê±´ë„ˆëœ€ (ì‚¬ìš©ì ì˜µì…˜)")
	}
	
	return deletedCount, nil
}

func FindDuplicates(files []*DriveFile, ds *DriveService) ([][]*DriveFile, error) {
	// ê¸°ì¡´ ì§„í–‰ ìƒíƒœ í™•ì¸
	progress, err := ds.loadProgress()
	if err != nil {
		log.Printf("âš ï¸ ì§„í–‰ ìƒíƒœ ë¡œë“œ ì‹¤íŒ¨: %v", err)
		progress = &ProgressData{Status: "idle"}
	}

	// ì´ë¯¸ ì™„ë£Œëœ ì¤‘ë³µ ê·¸ë£¹ì´ ìˆìœ¼ë©´ ë°˜í™˜
	if progress.Status == "completed" {
		log.Println("âœ… ì´ì „ì— ì™„ë£Œëœ ì¤‘ë³µ ê²€ì‚¬ ê²°ê³¼ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.")
		return ds.loadDuplicateGroups()
	}

	log.Println("ğŸ”¢ íŒŒì¼ì„ í¬ê¸°ë³„ë¡œ ê·¸ë£¹í™”í•˜ëŠ” ì¤‘...")
	sizeGroups := make(map[int64][]*DriveFile)
	
	for _, file := range files {
		sizeGroups[file.Size] = append(sizeGroups[file.Size], file)
	}

	// í¬ê¸°ê°€ ê°™ì€ íŒŒì¼ë“¤ë§Œ í•„í„°ë§
	var sizeGroupsSlice [][]*DriveFile
	for _, group := range sizeGroups {
		if len(group) >= 2 {
			sizeGroupsSlice = append(sizeGroupsSlice, group)
		}
	}

	potentialDuplicates := 0
	for _, group := range sizeGroupsSlice {
		potentialDuplicates += len(group)
	}
	log.Printf("ğŸ“Š ì ì¬ì  ì¤‘ë³µ í›„ë³´: %dê°œ íŒŒì¼ (í¬ê¸°ê°€ ê°™ì€ íŒŒì¼ë“¤)", potentialDuplicates)

	// ì§„í–‰ ìƒíƒœ ì´ˆê¸°í™”
	progress.TotalFiles = potentialDuplicates
	progress.Status = "running"
	progress.ProcessedFiles = 0
	progress.CompletedGroups = 0
	progress.CurrentGroup = 0
	ds.saveProgress(*progress)

	var duplicateGroups [][]*DriveFile
	processedFiles := 0
	
	for groupIndex, sameFiles := range sizeGroupsSlice {
		progress.CurrentGroup = groupIndex
		ds.saveProgress(*progress)

		log.Printf("ğŸ” ê·¸ë£¹ %d/%d: í¬ê¸° %d bytesì¸ íŒŒì¼ %dê°œì˜ í•´ì‹œ ê³„ì‚° ì¤‘...", 
			groupIndex+1, len(sizeGroupsSlice), sameFiles[0].Size, len(sameFiles))
		
		hashGroups := make(map[string][]*DriveFile)
		
		// ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì›Œì»¤ í’€ (ë™ì  ì„¤ì •)
		maxWorkers := ds.getMaxWorkers()
		log.Printf("âš™ï¸ ë³‘ë ¬ ì‘ì—… ê°œìˆ˜: %dê°œ", maxWorkers)
		semaphore := make(chan struct{}, maxWorkers)
		var wg sync.WaitGroup
		var mu sync.Mutex
		
		for i, file := range sameFiles {
			// ì´ë¯¸ í•´ì‹œê°€ ê³„ì‚°ëœ íŒŒì¼ì€ ê±´ë„ˆë›°ê¸°
			if file.Hash != "" {
				mu.Lock()
				hashGroups[file.Hash] = append(hashGroups[file.Hash], file)
				mu.Unlock()
				processedFiles++
				continue
			}

			wg.Add(1)
			go func(file *DriveFile, index int) {
				defer wg.Done()
				
				// ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œ ë‹¤ìš´ë¡œë“œ ì œí•œ
				semaphore <- struct{}{}
				defer func() { <-semaphore }()
				
				log.Printf("â¬‡ï¸  íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘ (%d/%d): %s", index+1, len(sameFiles), file.Name)
				
				content, err := ds.DownloadFileContent(file.ID)
				if err != nil {
					log.Printf("âŒ íŒŒì¼ %s ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: %v", file.Name, err)
					return
				}
				
				file.Hash = calculateHash(content)
				
				// DBì— í•´ì‹œ ì €ì¥
				if err := ds.updateFileHash(file.ID, file.Hash); err != nil {
					log.Printf("âš ï¸ í•´ì‹œ ì €ì¥ ì‹¤íŒ¨: %v", err)
				}
				
				mu.Lock()
				hashGroups[file.Hash] = append(hashGroups[file.Hash], file)
				processedFiles++
				progress.ProcessedFiles = processedFiles
				mu.Unlock()
				
				log.Printf("âœ… í•´ì‹œ ê³„ì‚° ì™„ë£Œ (%d/%d): %s", processedFiles, potentialDuplicates, file.Name)
				
				// 10ê°œë§ˆë‹¤ ì§„í–‰ ìƒíƒœ ì €ì¥
				if processedFiles%10 == 0 {
					ds.saveProgress(*progress)
				}
			}(file, i)
		}
		
		wg.Wait()
		
		// í•´ì‹œë³„ ê·¸ë£¹ì—ì„œ ì¤‘ë³µ ì°¾ê¸° ë° ì¦‰ì‹œ ì €ì¥
		for hash, hashFiles := range hashGroups {
			if len(hashFiles) >= 2 {
				log.Printf("ğŸ¯ ì¤‘ë³µ ë°œê²¬! í•´ì‹œ %s... : %dê°œ íŒŒì¼", hash[:8], len(hashFiles))
				duplicateGroups = append(duplicateGroups, hashFiles)
				
				// ì¦‰ì‹œ ì¤‘ë³µ ê·¸ë£¹ì„ DBì— ì €ì¥
				if err := ds.saveSingleDuplicateGroup(hashFiles); err != nil {
					log.Printf("âš ï¸ ì¤‘ë³µ ê·¸ë£¹ ì €ì¥ ì‹¤íŒ¨: %v", err)
				}
			}
		}
		
		progress.CompletedGroups = groupIndex + 1
		ds.saveProgress(*progress)
	}

	// ì™„ë£Œ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸
	progress.Status = "completed"
	progress.ProcessedFiles = processedFiles
	ds.saveProgress(*progress)

	log.Printf("ğŸ ì¤‘ë³µ ê²€ì‚¬ ì™„ë£Œ: %dê°œ íŒŒì¼ ì²˜ë¦¬ë¨", processedFiles)
	log.Printf("ğŸ“Š ì´ %dê°œ ì¤‘ë³µ ê·¸ë£¹ ë°œê²¬", len(duplicateGroups))
	return duplicateGroups, nil
}

// ì €ì¥ëœ í´ë” ë¹„êµ ì‘ì—… ì¡°íšŒ
func (ds *DriveService) getSavedComparisonTasks() ([]*FolderComparisonTask, error) {
	rows, err := ds.db.Query(`
		SELECT id, source_folder_id, target_folder_id, status, current_step,
		       source_folder_scanned, source_folder_total, target_folder_scanned, target_folder_total,
		       hashes_calculated, total_hashes_to_calc, duplicates_found, error_message,
		       created_at, updated_at
		FROM folder_comparison_tasks
		WHERE status IN ('pending', 'running', 'paused', 'completed')
		ORDER BY updated_at DESC
		LIMIT 10
	`)
	if err != nil {
		return nil, fmt.Errorf("ì €ì¥ëœ ì‘ì—… ì¡°íšŒ ì‹¤íŒ¨: %v", err)
	}
	defer rows.Close()

	var tasks []*FolderComparisonTask
	for rows.Next() {
		task := &FolderComparisonTask{}
		err := rows.Scan(
			&task.ID, &task.SourceFolderID, &task.TargetFolderID, &task.Status, &task.CurrentStep,
			&task.SourceFolderScanned, &task.SourceFolderTotal, &task.TargetFolderScanned, &task.TargetFolderTotal,
			&task.HashesCalculated, &task.TotalHashesToCalc, &task.DuplicatesFound, &task.ErrorMessage,
			&task.CreatedAt, &task.UpdatedAt,
		)
		if err != nil {
			log.Printf("âš ï¸ ì‘ì—… ì •ë³´ ìŠ¤ìº” ì‹¤íŒ¨: %v", err)
			continue
		}
		tasks = append(tasks, task)
	}

	return tasks, nil
}

// ì €ì¥ëœ í´ë” ë¹„êµ ì‘ì—… ëª¨ë‘ ì‚­ì œ
func (ds *DriveService) clearSavedComparisonTasks() error {
	tx, err := ds.db.Begin()
	if err != nil {
		return fmt.Errorf("íŠ¸ëœì­ì…˜ ì‹œì‘ ì‹¤íŒ¨: %v", err)
	}
	defer tx.Rollback()

	// ê´€ë ¨ í…Œì´ë¸”ë“¤ì˜ ë°ì´í„° ì‚­ì œ
	_, err = tx.Exec("DELETE FROM comparison_result_files")
	if err != nil {
		return fmt.Errorf("ë¹„êµ ê²°ê³¼ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: %v", err)
	}

	_, err = tx.Exec("DELETE FROM folder_comparison_tasks")
	if err != nil {
		return fmt.Errorf("ë¹„êµ ì‘ì—… ì‚­ì œ ì‹¤íŒ¨: %v", err)
	}

	err = tx.Commit()
	if err != nil {
		return fmt.Errorf("íŠ¸ëœì­ì…˜ ì»¤ë°‹ ì‹¤íŒ¨: %v", err)
	}

	log.Printf("âœ… ëª¨ë“  ì €ì¥ëœ í´ë” ë¹„êµ ì‘ì—…ì´ ì‚­ì œë¨")
	return nil
}